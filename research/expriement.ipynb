{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY= os.getenv(\"OPENAI_API_KEY\")\n",
    "# OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Generative AI -My Preparation\\\\Langchain-Project\\\\research'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Generative AI -My Preparation\\Langchain-Project\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Generative AI -My Preparation\\\\Langchain-Project'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"data/genai-principles.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'macOS Version 14.0 (Build 23A344) Quartz PDFContext', 'creator': 'Pages', 'creationdate': '2023-10-25T02:42:03+00:00', 'author': 'Karan Singh', 'moddate': '2023-10-25T09:40:35-04:00', 'title': 'GenAI-Principles', 'source': 'data/genai-principles.pdf', 'total_pages': 12, 'page': 0, 'page_label': '1'}, page_content='Karan Singh, Assistant Professor of Operations Research \\nPrinciples of Generative AI \\nA Technical Introduction \\nGenerative artificial intelligence (GenAI) tools are an emerging class of new-age artificial \\nintelligence algorithms capable of producing novel content — in varied formats such as text, \\naudio, video, pictures, and code — based on user prompts. Recent advances in machine \\nlearning (ML), massive datasets, and substantial increases in computing power have propelled \\nsuch tools to human-level performance on academic and professional benchmarks , 1\\ncomparable to the ninetieth percentile on the SAT and the bar exam. \\nThis rapid progress has led many  to to believe that the metamorphosis of these technologies 2\\nfrom research-grade demos to accessible and easy-to-use production-grade goods and \\nservices carries the potential to supercharge business processes and operations while enabling \\nentirely new deliverables heretofore rendered infeasible by economic or technological factors. It \\ntook OpenAI’s ChatGPT, a conversational web app based on a generative (multimodal) \\nlanguage model, about five days to reach one million users  (compared to 2.5 months for 3\\nInstagram). On the business side, the Economist reports that the number of jobs mentioning AI-\\nrelated skills quadrupled from 2022 to 2023. This enthusiasm has not gone unmet by investors. \\nGenerative AI startups reportedly raised 600% more capital in 2022 than in 2020 .   4\\n \\n 1\\nFigure 1: A taxonomy of GenAI-related disciplines.'),\n",
       " Document(metadata={'producer': 'macOS Version 14.0 (Build 23A344) Quartz PDFContext', 'creator': 'Pages', 'creationdate': '2023-10-25T02:42:03+00:00', 'author': 'Karan Singh', 'moddate': '2023-10-25T09:40:35-04:00', 'title': 'GenAI-Principles', 'source': 'data/genai-principles.pdf', 'total_pages': 12, 'page': 1, 'page_label': '2'}, page_content='Karan Singh, Assistant Professor of Operations Research \\nPurpose and Scope  \\nWhat are these new-era AI technologies? How do they function? What principles do they \\noperate on? What makes them different than already-hyped-up conventional machine learning \\n(ML) models? For what tasks is this class of technology most impactful? What future advances \\nmight one look forward to? These are the questions this report attempts to shed some light on. \\nThe report will also tease out how this understanding foundationally informs the best uses (and \\nmisuses) of GenAI in applied contexts. \\nA word of disclaimer: this gradient of topics also means that, while the initial sections deal with \\nfactual, if somewhat simplified, nuts-and-bolt workings of such models, the later sections delve \\ninto hopefully reasonable, but in a manner that only time may attest to, extrapolations and \\nspeculations, as necessitated by the developing nature of this technology and its current phase \\nin the technology adoption cycle. \\nWhile generative AI models come in many different shapes, utilizing varied statistical and \\ncomputational techniques to target various modalities, ranging from code and text to audio and \\nvideo, this report focuses almost exclusively on large language models (LLMs) capable of \\ngenerating novel text from textual prompts. This choice is partly due to the substantial lead \\nLLMs have in driving the overall usage of generative AI models  and partly due to the centrality 5\\nof language in formulating and addressing commonplace information-processing tasks. That \\nsaid, image- and code-based GenAI models have already witnessed successful commercial \\nproduct deployment, for example, by Adobe for creating visual content and by Github as a \\nprogramming assistance tool.   \\n 2\\nFigure 2: An image-\\nbased GenAI model, \\nMidjourney’s response to \\nthe prompt — \\n“Businessman in Tokyo \\namidst rush hour, his \\ngaze fixed ahead, \\nsurrounded by a sea of \\nblack umbrellas.”\\nFigure 3: Based on a code-based GenAI model, OpenAI Codex, \\nGithub Copilot is a commercial tool that can generate functional \\ncode from specifications given as natural language. Reportedly, as \\nof June 2023, it served over a million users.'),\n",
       " Document(metadata={'producer': 'macOS Version 14.0 (Build 23A344) Quartz PDFContext', 'creator': 'Pages', 'creationdate': '2023-10-25T02:42:03+00:00', 'author': 'Karan Singh', 'moddate': '2023-10-25T09:40:35-04:00', 'title': 'GenAI-Principles', 'source': 'data/genai-principles.pdf', 'total_pages': 12, 'page': 2, 'page_label': '3'}, page_content='Karan Singh, Assistant Professor of Operations Research \\nA Quick First Introduction to Language Models \\nAt its core, a language model implements a simple functionality— to predict the next word (or \\ntoken) given a context window specifying preceding words. More precisely, given a context \\nwindow, a language model outputs a probability distribution over all possible words in its \\nvocabulary, indicating the probability with which each possible word follows the given list of \\nwords. Upon sampling  a guess of the next word from the said distribution, the language model 6\\nincrementally repeats this ostensibly primitive step to produce a more extensive body of text.    \\n \\nWe make two observations here: \\n1. Completions are random. The predicted completion, given a context window, is not \\ndeterministic. Sampling the next word in each step from the output distribution introduces \\nenough randomness to permit that the predicted completions could be meaningfully \\ndifferent on every fresh run. This stochasticity is why ChatGPT, for instance, can offer \\nvaried answers for the same prompt across successive runs. Replacing the sampling step \\nwith choosing (greedily) the most likely immediate word is known to degrade the quality of \\nthe produced text. The randomness in responses is also desirable from a user \\n 3\\nFigure 4: A probabilistic model predicting the next word coupled with sampling can produce \\nlarger bodies of text.'),\n",
       " Document(metadata={'producer': 'macOS Version 14.0 (Build 23A344) Quartz PDFContext', 'creator': 'Pages', 'creationdate': '2023-10-25T02:42:03+00:00', 'author': 'Karan Singh', 'moddate': '2023-10-25T09:40:35-04:00', 'title': 'GenAI-Principles', 'source': 'data/genai-principles.pdf', 'total_pages': 12, 'page': 3, 'page_label': '4'}, page_content='Karan Singh, Assistant Professor of Operations Research \\nperspective in getting varied responses. From the deployer’s perspective, this optionally \\nallows the model to gather user feedback regarding the quality of seemingly plausible \\nresponses. This choice partly also contributes to hallucination in language models. \\n2. Initial prompt matters. Language models are conditional probabilistic models. They \\nproduce a completion conditioned on the initial set of words. In this way, the initial context \\nwindow, termed prompt, matters crucially to the produced completion. One hallmark of \\nmodern language models is that they keep track of the initial prompt even when \\ngenerating large bodies of text, unlike the earlier generation of models, thus producing \\nmore coherent responses. Artful and cleverly crafted prompts can significantly improve \\nthe quality and utility of the synthesized text. Prompt engineering , for example, practices 7\\nthat encourage the language model to solve a problem by decomposing it into \\nintermediate subproblems, has been known to improve the performance on logical \\nreasoning tasks. \\nContextualizing LLMs in terms of Recent AI Advances \\nAlthough we describe the text generation procedure above, many questions still need to be \\naddressed: How do language models function internally? How are the output probabilities for \\nthe next word determined? What goes into creating (and indeed using) a language model? How \\nare language models different from more traditional predictive models if all they do is predict the \\nnext token? \\nWe address these questions indirectly in the present section by taking a tour of the essential \\nsignificant developments in machine learning and artificial intelligence that have occurred in the \\nlast decade and have fueled the creation of modern large language models. \\nClassical Machine Learning as Prediction Machines \\nWe start with the most well-understood subset of machine learning techniques: supervised \\nlearning. The central objective in supervised learning is to produce a prediction rule that predicts \\nwell on unseen data, given enough labeled examples. For example, consider predicting house \\nprices from the square footage in a given zip code. Instead of creating a hand-crafted prediction \\nrule, the machine learning methodology advocates for choosing a prediction rule from an \\nexpressive but non-exhaustive class of rules, such as linear predictors, that provides the best fit \\non an existing collection of size-price examples. The statistically well-substantiated leap of faith \\nhere is that we expect (or at least hope) that a parsimonious prediction rule that predicts well on \\ncollected data, for which we know the correct answers, continues to maintain its predictive edge \\non unseen data, where answers or prices are unknown. Such a predictive methodology benefits \\nfrom an abundance of labeled examples, hoping that a prediction rule learned from more \\nexamples is more robust in that its superior predictive performance on seen data is less \\nascribable to chance alone. Another example of a supervised learning task is to separate spam \\nfrom non-spam mail, given the text in email messages. Again, having more examples of spam \\nand non-spam emails is helpful to a supervised learning algorithm. \\n 4'),\n",
       " Document(metadata={'producer': 'macOS Version 14.0 (Build 23A344) Quartz PDFContext', 'creator': 'Pages', 'creationdate': '2023-10-25T02:42:03+00:00', 'author': 'Karan Singh', 'moddate': '2023-10-25T09:40:35-04:00', 'title': 'GenAI-Principles', 'source': 'data/genai-principles.pdf', 'total_pages': 12, 'page': 4, 'page_label': '5'}, page_content='Karan Singh, Assistant Professor of Operations Research \\n \\nCharacteristics common to both language models and supervised learning: \\n1. Predicting Well is the Yardstick. A prediction rule is good as long as it makes \\nreasonable predictions on average. Compared to more ambitious sub-disciplines in \\nstatistics, any statements about causality, p-values, and recovering latent structure are \\nabsent. We are similarly impervious to such considerations in language models. Such \\nsimplicity of goals enables very flexible prediction rules in machine learning. Although \\nseeming modest in its aim, the art of machine learning has long been to cast as many \\ndisparate problems as questions about prediction as possible. Predicting house prices \\nfrom square footage is a regular regression task. But, for reverse image captioning, is \\n“predicting” a (high-dimensional) image given a few words a reasonable or well-defined \\nclassification task? Yet, this is how machine learning algorithms function. \\n2. Model Agnosticism. Supervised learning algorithms realize the adage that all models \\nare wrong, but some are useful. For example, when building the price predictor above, a \\ndata scientist does not believe that the genuine relationship between prices and area is \\nlinear or well-specified. Similarly, when using neural networks to predict the next word in \\nlanguage models, we don’t believe that this is how Shakespeare must have employed a \\nneural network to compose his texts. \\nYet, there are crucial differences: \\n 5\\nFigure 5: Predicting house prices from square footage. Pictured is a linear \\nregression, an example of a supervised learning algorithm that uses extant \\ndata to learn a linear predictor.'),\n",
       " Document(metadata={'producer': 'macOS Version 14.0 (Build 23A344) Quartz PDFContext', 'creator': 'Pages', 'creationdate': '2023-10-25T02:42:03+00:00', 'author': 'Karan Singh', 'moddate': '2023-10-25T09:40:35-04:00', 'title': 'GenAI-Principles', 'source': 'data/genai-principles.pdf', 'total_pages': 12, 'page': 5, 'page_label': '6'}, page_content='Karan Singh, Assistant Professor of Operations Research \\n1. Fidelity of Seen Data vs. Unseen Data. Classical supervised learning operates on the \\nassumption that seen data must be representative of unseen data in a particular sense, \\nnamely that any fixed example is equally likely to be in the seen or unseen bucket. In the \\nabsence of temporal effects, this is reasonable for house prices. More generally, \\nsupervised learning requires a well-curated dataset that is closely aligned with the \\nprediction task at hand. But, as we will see, language models are trained on vast corpora \\nof somewhat ruthlessly collected texts from the internet. Yet, completing a random partial \\nsentence from the internet is presumably not what businesses using language models \\ncare about. \\nDeep Learning as Automated Representation Learning \\nAlthough useful for panel or tabular data, pre-deep-learning-era supervised algorithms struggled \\nto predict well when presented with visual or auditory inputs. Although the promise of machine \\nlearning is predicated on the automation of learning, in practice, supervised learning algorithms \\nrequire carefully crafted representations of input data in which operations like additions and \\nmultiplications, for example, for linear regression, were semantically relevant. Decades of \\npainstaking research in signal processing and computer vision had resulted in domain-specific \\nhand-crafted representations, each useful for a specific modality (images, audio, or video). The \\npredictive performance of ML algorithms was limited by how good such representations were. \\n 6\\nFigure 6: A typical deep neural network for recognizing faces. Each \\nsuccessive layer progressively learns higher-level representations (from \\nedges to contours to faces).'),\n",
       " Document(metadata={'producer': 'macOS Version 14.0 (Build 23A344) Quartz PDFContext', 'creator': 'Pages', 'creationdate': '2023-10-25T02:42:03+00:00', 'author': 'Karan Singh', 'moddate': '2023-10-25T09:40:35-04:00', 'title': 'GenAI-Principles', 'source': 'data/genai-principles.pdf', 'total_pages': 12, 'page': 6, 'page_label': '7'}, page_content='Karan Singh, Assistant Professor of Operations Research \\nThe revolution in deep learning was to automate the process of representation learning itself. \\nDeep learning uses neural networks with multiple layers, each layer incrementally converting \\nthe data into a more manageable form, all to make better predictions. This form of automated \\nhierarchical representation learning heralded a decade of tremendous progress in image and \\nspeech recognition and machine translation, starting with the breakthrough work of Krizhevsky, \\nSutskever, and Hinton  in 2012 on the Imagenet challenge. Taking advantage of GPUs (a form 8\\nof shared-memory parallel computing) and the availability of a large public dataset, this seminal \\nwork slashed the error rate for image recognition by a substantial multiple. Parallel gains were \\nlater realized using similar deep neural network architectures in speech recognition and other \\nmachine learning domains. In this sense, the advances deep learning enabled were (relatively) \\ndomain agnostic. \\nAlthough deep neural networks are data-hungry in that they require a substantially large dataset \\nto start predicting well, they also successfully realize a long-promised advantage of neural \\nnetworks. This factor is crucial to the practice of modern-day machine learning. In the process of \\nhierarchically learning representations, deep nets learn task- (or label--) agnostic features of the \\ndataset in the lower layers, while higher layers closer to the output account for task-specific \\nrepresentations. This permits us to (a) train a deep net to separate images of cats and dogs on \\na large dataset and (b) subsequently build a shallow (even linear) performant neural net that \\nuses the lower layers of the former to craft useful representations to classify images of zebra \\nand giraffes. Step A is often called pre-training, and step B is referred to as supervised fine-\\ntuning. This manner of amortizing the learning across tasks that are not individually data-rich is \\ncentral to language models. \\nWord Embeddings and Contrastive Learning \\nWhile the progress of deep learning in speech and audio was made possible by the availability \\nof large crowd-labeled datasets (with 10s of millions of annotated images), such large high-\\nquality datasets were absent in the textual domain, despite a plethora of unlabelled data in the \\nform of books, Wikipedia articles, and articles on the internet. Could a machine learning \\nalgorithm make use of the cheap, unlabelled data instead? \\nIn computational linguistics, the distributional hypothesis codifies an appealing and intuitive idea \\nthat similar words occur in similar contexts. In 2013, inspired by this observation, Mikolov et al  9\\ntrained a neural network, termed Word2Vec, to predict randomly selected words in a text corpus \\ngiven neighboring words for each. Note that this step doesn’t require any need human \\nannotators. They observed that the 300-dimensional vector representations the neural net \\nlearned for words had excellent linear algebraic properties that transparently reflected the \\nunderlying semantics. For example, one obtained Queen when queried for the word with the \\nvector closest to King - Man + Woman. Thus, each vector dimension captured some abstract \\nsemantic degree of freedom. These representations were also valuable for natural classification \\ntasks with limited data, such as sentiment classification, given a small number of examples. \\n 7'),\n",
       " Document(metadata={'producer': 'macOS Version 14.0 (Build 23A344) Quartz PDFContext', 'creator': 'Pages', 'creationdate': '2023-10-25T02:42:03+00:00', 'author': 'Karan Singh', 'moddate': '2023-10-25T09:40:35-04:00', 'title': 'GenAI-Principles', 'source': 'data/genai-principles.pdf', 'total_pages': 12, 'page': 7, 'page_label': '8'}, page_content='Karan Singh, Assistant Professor of Operations Research \\n \\nThe approach of creating auxiliary labeling tasks for free from unlabelled data to learn \\nsemantically relevant representation is called contrastive learning and has proved helpful in \\nother domains, too. For example, given a set of unlabelled images, a classifier trained to \\nrecognize random crops from the same image as a positive match and those from distinct \\nimages as a negative match (pre-training step) learns representations useful for supervised fine-\\ntuning on genuine classification tasks downstream. \\nTransformers mollify the Optimization Landscape \\nWhile word embeddings serve as proof that textual semantic regularities can be assessed \\nwithout labeled data, substantive language processing tasks need an algorithmic \\nimplementation of the concept of memory to capture relationships between words that are \\npositionally far apart. For example, a common motif in stories is that the next act derives from \\nsome event that occurred a while ago.  \\n 8\\nFigure 7: Vector space representations of words exhibit linear algebraic \\nrelationships between semantic units and can be used to answer analogy \\nquestions, e.g., son - father + mother = daughter.\\nFigure 8: RNNs capture memory effects by sequentially processing \\ninformation.'),\n",
       " Document(metadata={'producer': 'macOS Version 14.0 (Build 23A344) Quartz PDFContext', 'creator': 'Pages', 'creationdate': '2023-10-25T02:42:03+00:00', 'author': 'Karan Singh', 'moddate': '2023-10-25T09:40:35-04:00', 'title': 'GenAI-Principles', 'source': 'data/genai-principles.pdf', 'total_pages': 12, 'page': 8, 'page_label': '9'}, page_content='Karan Singh, Assistant Professor of Operations Research \\nThe first generation of neural networks that captured the notion of memory were Recurrent \\nNeural Networks (RNNs), by sequentially processing a piece of text one word at a time while \\nupdating an internal state to maintain continuity, a proxy for memory. Unfortunately, optimizing \\nsuch recurrent neural nets to find one that best fits a given dataset proved extra-ordinarily error-\\nprone and challenging. \\nIn 2017, Vaswani et al  introduced a different neural network architecture, termed transformer, 10\\nthat could efficiently capture long-range relations between tokens compactly (non-sequentially) \\nby processing the entire surrounding context window at once while remaining amenable to \\ngradient-based optimization. The introduction of transformers spurred a line of research on \\nlanguage models, culminating in training models with an increasingly higher number of \\nparameters trained on ever larger datasets. For example, GPT2 (Generative Pre-trained \\nTransformer 2), released in 2019, is a 1.5 billion parameter model trained on 40 GB of data, \\nwhile GPT3, released in 2020, is a 175 billion parameter model trained on 570 GB of text data. \\nWhile larger models resulted in better performance, the open-market cost for training these \\nenormous models was estimated to be tens of millions of dollars. \\n \\nGeneral-Purpose Language Models: Supervised Fine-tuning & GPT3 \\nThe general paradigm brought about by contrastive learning was first to learn a large model on \\nauxiliary tasks created using an unlabelled dataset (the pre-training step) and subsequently to \\nuse these learned representations in a downstream supervised learning task given a few task-\\nspecific labeled examples (the supervised fine-tuning step). While broadly useful and practical, \\nsupervised fine-tuning requires replicas of the baseline pre-trained model for each downstream \\n 9\\nFigure 9: The LLM arms race with exponentially increasing \\nparameter counts. (Credit: HuggingFace)'),\n",
       " Document(metadata={'producer': 'macOS Version 14.0 (Build 23A344) Quartz PDFContext', 'creator': 'Pages', 'creationdate': '2023-10-25T02:42:03+00:00', 'author': 'Karan Singh', 'moddate': '2023-10-25T09:40:35-04:00', 'title': 'GenAI-Principles', 'source': 'data/genai-principles.pdf', 'total_pages': 12, 'page': 9, 'page_label': '10'}, page_content='Karan Singh, Assistant Professor of Operations Research \\ntask; further, the large size of language models makes running even a few steps of gradient-\\nbased iterative optimization for supervised learning prohibitive except on computationally \\nexpensive hardware setups. \\nThe paper  describing the architecture of the GPT3 model presents a far cheaper and more 11\\nconvenient way of repurposing pre-trained language models for specific downstream tasks, \\nnamely, by specifying a few labeled examples in the prompt before asking for a label or \\nresponse for unseen data. This mode of inference, in-context learning, does not require \\ncomputationally expensive adjustments to the weights or parameters of an LLM and instead \\ntreats the entire downstream supervised task as a prompt for the language model to complete. \\nThis makes LLMs very attractive for end-users, who no longer have to create copies of the large \\nmodel to customize, nor do they have to run a sophisticated optimization procedure to adjust \\nparameters; each downstream task, in effect, becomes a conversation. While fine-tuning may \\nstill result in additional performance gains over in-context learning for some tasks in exchange \\nfor a massive increase in computational load, a crucial advance of GPT3 is that this \\nsubstantially lowers this gap, democratizing the use (although not the training) of LLMs. \\n \\n 10\\nFigure 10: An illustration of in-context learning. GPT4 figures out the \\ncorrect pattern that the answer is the first number + reverse of the \\nsecond, given two examples.'),\n",
       " Document(metadata={'producer': 'macOS Version 14.0 (Build 23A344) Quartz PDFContext', 'creator': 'Pages', 'creationdate': '2023-10-25T02:42:03+00:00', 'author': 'Karan Singh', 'moddate': '2023-10-25T09:40:35-04:00', 'title': 'GenAI-Principles', 'source': 'data/genai-principles.pdf', 'total_pages': 12, 'page': 10, 'page_label': '11'}, page_content='Karan Singh, Assistant Professor of Operations Research \\nTowards Conversational AI: Learning from Human Feedback \\nWhile GPT3-like models happen to be good at conversation-centered tasks, they are not \\nexplicitly trained or incentivized to follow instructions. OpenAI’s InstructGPT model  post pre-12\\ntraining aligns the model to follow the users’ instructions by fine-tuning the model to mimic \\nlabeled demonstrations of the desired behavior (via supervised learning) and highly-ranked \\nresponses to prompts as collected using human feedback (via reinforcement learning). \\n \\nThe Future: Foundation Models \\nGiven the success of language models, there has been increased interest in the possibility of \\nrecreating the magic of LLMs in other domains. Such models, generically termed foundation \\nmodels, attempt to amortize the cost of limited-data downstream tasks by pre-training on large \\ncorpora of broadly related tasks or unlabelled datasets. For example, one might be able to \\nrepurpose the LLM paradigm to train a generalist robot or decision-making agent that learns \\nfrom supply chain operations across all industries. \\nConclusion \\nThis report contextualizes large-language models within the more extensive machine learning \\nand artificial intelligence landscape by training the origins of the principal ideas that fuel today’s \\nlarge language models. By bringing out their essential characteristics and differences against \\ntraditional modes of machine learning, we hope that a user of such models can be better \\n 11\\nFigure 11: While GPT3 performs text completion by guessing the \\nmost plausible completion, InstructGPT has been explicitly \\ntrained to follow instructions. (Credit: OpenAI’s web report)'),\n",
       " Document(metadata={'producer': 'macOS Version 14.0 (Build 23A344) Quartz PDFContext', 'creator': 'Pages', 'creationdate': '2023-10-25T02:42:03+00:00', 'author': 'Karan Singh', 'moddate': '2023-10-25T09:40:35-04:00', 'title': 'GenAI-Principles', 'source': 'data/genai-principles.pdf', 'total_pages': 12, 'page': 11, 'page_label': '12'}, page_content='Karan Singh, Assistant Professor of Operations Research \\ninformed of the underlying tradeoffs such models induce, e.g., the performance-resource \\ntradeoffs between fine-tuning and in-context learning. \\nEndnotes \\n See the ﬁrst table on OpenAI’s announcement for an overview of GPT4’s performance on other academic, 1\\nprofessional and programming exams. The quoted nineMeth percenMle performance on the bar exam was assessed \\nby Katz et al, but others have raised concerns. \\n See quotes by industry and research leaders here.2\\n See iniMal consumer adopMon staMsMcs for ChatGPT here and here.3\\n See this reporMng for investments in GenAI.4\\n See current and project user bases for GenAI here.5\\n When producing text, rather than sampling the next word incrementally, a more systemaMc search operaMon 6\\ntermed Beam Search, coined by Raj Reddy at CMU, oXen yields beYer results.\\n Structuring iniMal text to elicit useful outputs from GenAI model is called prompt engineering.7\\n See the full Krizhevshy, Sutskever, Hinton paper here.8\\n See the Word2Vec paper here.9\\n See the paper that introduced Transformers here.10\\n See the GPT3 paper here.11\\n See the instruct GPT paper here.12\\n 12')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_gen = \"\"\n",
    "for page in data:\n",
    "    question_gen += page.page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Karan Singh, Assistant Professor of Operations Research \\nPrinciples of Generative AI \\nA Technical Introduction \\nGenerative artificial intelligence (GenAI) tools are an emerging class of new-age artificial \\nintelligence algorithms capable of producing novel content — in varied formats such as text, \\naudio, video, pictures, and code — based on user prompts. Recent advances in machine \\nlearning (ML), massive datasets, and substantial increases in computing power have propelled \\nsuch tools to human-level performance on academic and professional benchmarks , 1\\ncomparable to the ninetieth percentile on the SAT and the bar exam. \\nThis rapid progress has led many  to to believe that the metamorphosis of these technologies 2\\nfrom research-grade demos to accessible and easy-to-use production-grade goods and \\nservices carries the potential to supercharge business processes and operations while enabling \\nentirely new deliverables heretofore rendered infeasible by economic or technological factors. It \\ntook OpenAI’s ChatGPT, a conversational web app based on a generative (multimodal) \\nlanguage model, about five days to reach one million users  (compared to 2.5 months for 3\\nInstagram). On the business side, the Economist reports that the number of jobs mentioning AI-\\nrelated skills quadrupled from 2022 to 2023. This enthusiasm has not gone unmet by investors. \\nGenerative AI startups reportedly raised 600% more capital in 2022 than in 2020 .   4\\n \\n 1\\nFigure 1: A taxonomy of GenAI-related disciplines.Karan Singh, Assistant Professor of Operations Research \\nPurpose and Scope  \\nWhat are these new-era AI technologies? How do they function? What principles do they \\noperate on? What makes them different than already-hyped-up conventional machine learning \\n(ML) models? For what tasks is this class of technology most impactful? What future advances \\nmight one look forward to? These are the questions this report attempts to shed some light on. \\nThe report will also tease out how this understanding foundationally informs the best uses (and \\nmisuses) of GenAI in applied contexts. \\nA word of disclaimer: this gradient of topics also means that, while the initial sections deal with \\nfactual, if somewhat simplified, nuts-and-bolt workings of such models, the later sections delve \\ninto hopefully reasonable, but in a manner that only time may attest to, extrapolations and \\nspeculations, as necessitated by the developing nature of this technology and its current phase \\nin the technology adoption cycle. \\nWhile generative AI models come in many different shapes, utilizing varied statistical and \\ncomputational techniques to target various modalities, ranging from code and text to audio and \\nvideo, this report focuses almost exclusively on large language models (LLMs) capable of \\ngenerating novel text from textual prompts. This choice is partly due to the substantial lead \\nLLMs have in driving the overall usage of generative AI models  and partly due to the centrality 5\\nof language in formulating and addressing commonplace information-processing tasks. That \\nsaid, image- and code-based GenAI models have already witnessed successful commercial \\nproduct deployment, for example, by Adobe for creating visual content and by Github as a \\nprogramming assistance tool.   \\n 2\\nFigure 2: An image-\\nbased GenAI model, \\nMidjourney’s response to \\nthe prompt — \\n“Businessman in Tokyo \\namidst rush hour, his \\ngaze fixed ahead, \\nsurrounded by a sea of \\nblack umbrellas.”\\nFigure 3: Based on a code-based GenAI model, OpenAI Codex, \\nGithub Copilot is a commercial tool that can generate functional \\ncode from specifications given as natural language. Reportedly, as \\nof June 2023, it served over a million users.Karan Singh, Assistant Professor of Operations Research \\nA Quick First Introduction to Language Models \\nAt its core, a language model implements a simple functionality— to predict the next word (or \\ntoken) given a context window specifying preceding words. More precisely, given a context \\nwindow, a language model outputs a probability distribution over all possible words in its \\nvocabulary, indicating the probability with which each possible word follows the given list of \\nwords. Upon sampling  a guess of the next word from the said distribution, the language model 6\\nincrementally repeats this ostensibly primitive step to produce a more extensive body of text.    \\n \\nWe make two observations here: \\n1. Completions are random. The predicted completion, given a context window, is not \\ndeterministic. Sampling the next word in each step from the output distribution introduces \\nenough randomness to permit that the predicted completions could be meaningfully \\ndifferent on every fresh run. This stochasticity is why ChatGPT, for instance, can offer \\nvaried answers for the same prompt across successive runs. Replacing the sampling step \\nwith choosing (greedily) the most likely immediate word is known to degrade the quality of \\nthe produced text. The randomness in responses is also desirable from a user \\n 3\\nFigure 4: A probabilistic model predicting the next word coupled with sampling can produce \\nlarger bodies of text.Karan Singh, Assistant Professor of Operations Research \\nperspective in getting varied responses. From the deployer’s perspective, this optionally \\nallows the model to gather user feedback regarding the quality of seemingly plausible \\nresponses. This choice partly also contributes to hallucination in language models. \\n2. Initial prompt matters. Language models are conditional probabilistic models. They \\nproduce a completion conditioned on the initial set of words. In this way, the initial context \\nwindow, termed prompt, matters crucially to the produced completion. One hallmark of \\nmodern language models is that they keep track of the initial prompt even when \\ngenerating large bodies of text, unlike the earlier generation of models, thus producing \\nmore coherent responses. Artful and cleverly crafted prompts can significantly improve \\nthe quality and utility of the synthesized text. Prompt engineering , for example, practices 7\\nthat encourage the language model to solve a problem by decomposing it into \\nintermediate subproblems, has been known to improve the performance on logical \\nreasoning tasks. \\nContextualizing LLMs in terms of Recent AI Advances \\nAlthough we describe the text generation procedure above, many questions still need to be \\naddressed: How do language models function internally? How are the output probabilities for \\nthe next word determined? What goes into creating (and indeed using) a language model? How \\nare language models different from more traditional predictive models if all they do is predict the \\nnext token? \\nWe address these questions indirectly in the present section by taking a tour of the essential \\nsignificant developments in machine learning and artificial intelligence that have occurred in the \\nlast decade and have fueled the creation of modern large language models. \\nClassical Machine Learning as Prediction Machines \\nWe start with the most well-understood subset of machine learning techniques: supervised \\nlearning. The central objective in supervised learning is to produce a prediction rule that predicts \\nwell on unseen data, given enough labeled examples. For example, consider predicting house \\nprices from the square footage in a given zip code. Instead of creating a hand-crafted prediction \\nrule, the machine learning methodology advocates for choosing a prediction rule from an \\nexpressive but non-exhaustive class of rules, such as linear predictors, that provides the best fit \\non an existing collection of size-price examples. The statistically well-substantiated leap of faith \\nhere is that we expect (or at least hope) that a parsimonious prediction rule that predicts well on \\ncollected data, for which we know the correct answers, continues to maintain its predictive edge \\non unseen data, where answers or prices are unknown. Such a predictive methodology benefits \\nfrom an abundance of labeled examples, hoping that a prediction rule learned from more \\nexamples is more robust in that its superior predictive performance on seen data is less \\nascribable to chance alone. Another example of a supervised learning task is to separate spam \\nfrom non-spam mail, given the text in email messages. Again, having more examples of spam \\nand non-spam emails is helpful to a supervised learning algorithm. \\n 4Karan Singh, Assistant Professor of Operations Research \\n \\nCharacteristics common to both language models and supervised learning: \\n1. Predicting Well is the Yardstick. A prediction rule is good as long as it makes \\nreasonable predictions on average. Compared to more ambitious sub-disciplines in \\nstatistics, any statements about causality, p-values, and recovering latent structure are \\nabsent. We are similarly impervious to such considerations in language models. Such \\nsimplicity of goals enables very flexible prediction rules in machine learning. Although \\nseeming modest in its aim, the art of machine learning has long been to cast as many \\ndisparate problems as questions about prediction as possible. Predicting house prices \\nfrom square footage is a regular regression task. But, for reverse image captioning, is \\n“predicting” a (high-dimensional) image given a few words a reasonable or well-defined \\nclassification task? Yet, this is how machine learning algorithms function. \\n2. Model Agnosticism. Supervised learning algorithms realize the adage that all models \\nare wrong, but some are useful. For example, when building the price predictor above, a \\ndata scientist does not believe that the genuine relationship between prices and area is \\nlinear or well-specified. Similarly, when using neural networks to predict the next word in \\nlanguage models, we don’t believe that this is how Shakespeare must have employed a \\nneural network to compose his texts. \\nYet, there are crucial differences: \\n 5\\nFigure 5: Predicting house prices from square footage. Pictured is a linear \\nregression, an example of a supervised learning algorithm that uses extant \\ndata to learn a linear predictor.Karan Singh, Assistant Professor of Operations Research \\n1. Fidelity of Seen Data vs. Unseen Data. Classical supervised learning operates on the \\nassumption that seen data must be representative of unseen data in a particular sense, \\nnamely that any fixed example is equally likely to be in the seen or unseen bucket. In the \\nabsence of temporal effects, this is reasonable for house prices. More generally, \\nsupervised learning requires a well-curated dataset that is closely aligned with the \\nprediction task at hand. But, as we will see, language models are trained on vast corpora \\nof somewhat ruthlessly collected texts from the internet. Yet, completing a random partial \\nsentence from the internet is presumably not what businesses using language models \\ncare about. \\nDeep Learning as Automated Representation Learning \\nAlthough useful for panel or tabular data, pre-deep-learning-era supervised algorithms struggled \\nto predict well when presented with visual or auditory inputs. Although the promise of machine \\nlearning is predicated on the automation of learning, in practice, supervised learning algorithms \\nrequire carefully crafted representations of input data in which operations like additions and \\nmultiplications, for example, for linear regression, were semantically relevant. Decades of \\npainstaking research in signal processing and computer vision had resulted in domain-specific \\nhand-crafted representations, each useful for a specific modality (images, audio, or video). The \\npredictive performance of ML algorithms was limited by how good such representations were. \\n 6\\nFigure 6: A typical deep neural network for recognizing faces. Each \\nsuccessive layer progressively learns higher-level representations (from \\nedges to contours to faces).Karan Singh, Assistant Professor of Operations Research \\nThe revolution in deep learning was to automate the process of representation learning itself. \\nDeep learning uses neural networks with multiple layers, each layer incrementally converting \\nthe data into a more manageable form, all to make better predictions. This form of automated \\nhierarchical representation learning heralded a decade of tremendous progress in image and \\nspeech recognition and machine translation, starting with the breakthrough work of Krizhevsky, \\nSutskever, and Hinton  in 2012 on the Imagenet challenge. Taking advantage of GPUs (a form 8\\nof shared-memory parallel computing) and the availability of a large public dataset, this seminal \\nwork slashed the error rate for image recognition by a substantial multiple. Parallel gains were \\nlater realized using similar deep neural network architectures in speech recognition and other \\nmachine learning domains. In this sense, the advances deep learning enabled were (relatively) \\ndomain agnostic. \\nAlthough deep neural networks are data-hungry in that they require a substantially large dataset \\nto start predicting well, they also successfully realize a long-promised advantage of neural \\nnetworks. This factor is crucial to the practice of modern-day machine learning. In the process of \\nhierarchically learning representations, deep nets learn task- (or label--) agnostic features of the \\ndataset in the lower layers, while higher layers closer to the output account for task-specific \\nrepresentations. This permits us to (a) train a deep net to separate images of cats and dogs on \\na large dataset and (b) subsequently build a shallow (even linear) performant neural net that \\nuses the lower layers of the former to craft useful representations to classify images of zebra \\nand giraffes. Step A is often called pre-training, and step B is referred to as supervised fine-\\ntuning. This manner of amortizing the learning across tasks that are not individually data-rich is \\ncentral to language models. \\nWord Embeddings and Contrastive Learning \\nWhile the progress of deep learning in speech and audio was made possible by the availability \\nof large crowd-labeled datasets (with 10s of millions of annotated images), such large high-\\nquality datasets were absent in the textual domain, despite a plethora of unlabelled data in the \\nform of books, Wikipedia articles, and articles on the internet. Could a machine learning \\nalgorithm make use of the cheap, unlabelled data instead? \\nIn computational linguistics, the distributional hypothesis codifies an appealing and intuitive idea \\nthat similar words occur in similar contexts. In 2013, inspired by this observation, Mikolov et al  9\\ntrained a neural network, termed Word2Vec, to predict randomly selected words in a text corpus \\ngiven neighboring words for each. Note that this step doesn’t require any need human \\nannotators. They observed that the 300-dimensional vector representations the neural net \\nlearned for words had excellent linear algebraic properties that transparently reflected the \\nunderlying semantics. For example, one obtained Queen when queried for the word with the \\nvector closest to King - Man + Woman. Thus, each vector dimension captured some abstract \\nsemantic degree of freedom. These representations were also valuable for natural classification \\ntasks with limited data, such as sentiment classification, given a small number of examples. \\n 7Karan Singh, Assistant Professor of Operations Research \\n \\nThe approach of creating auxiliary labeling tasks for free from unlabelled data to learn \\nsemantically relevant representation is called contrastive learning and has proved helpful in \\nother domains, too. For example, given a set of unlabelled images, a classifier trained to \\nrecognize random crops from the same image as a positive match and those from distinct \\nimages as a negative match (pre-training step) learns representations useful for supervised fine-\\ntuning on genuine classification tasks downstream. \\nTransformers mollify the Optimization Landscape \\nWhile word embeddings serve as proof that textual semantic regularities can be assessed \\nwithout labeled data, substantive language processing tasks need an algorithmic \\nimplementation of the concept of memory to capture relationships between words that are \\npositionally far apart. For example, a common motif in stories is that the next act derives from \\nsome event that occurred a while ago.  \\n 8\\nFigure 7: Vector space representations of words exhibit linear algebraic \\nrelationships between semantic units and can be used to answer analogy \\nquestions, e.g., son - father + mother = daughter.\\nFigure 8: RNNs capture memory effects by sequentially processing \\ninformation.Karan Singh, Assistant Professor of Operations Research \\nThe first generation of neural networks that captured the notion of memory were Recurrent \\nNeural Networks (RNNs), by sequentially processing a piece of text one word at a time while \\nupdating an internal state to maintain continuity, a proxy for memory. Unfortunately, optimizing \\nsuch recurrent neural nets to find one that best fits a given dataset proved extra-ordinarily error-\\nprone and challenging. \\nIn 2017, Vaswani et al  introduced a different neural network architecture, termed transformer, 10\\nthat could efficiently capture long-range relations between tokens compactly (non-sequentially) \\nby processing the entire surrounding context window at once while remaining amenable to \\ngradient-based optimization. The introduction of transformers spurred a line of research on \\nlanguage models, culminating in training models with an increasingly higher number of \\nparameters trained on ever larger datasets. For example, GPT2 (Generative Pre-trained \\nTransformer 2), released in 2019, is a 1.5 billion parameter model trained on 40 GB of data, \\nwhile GPT3, released in 2020, is a 175 billion parameter model trained on 570 GB of text data. \\nWhile larger models resulted in better performance, the open-market cost for training these \\nenormous models was estimated to be tens of millions of dollars. \\n \\nGeneral-Purpose Language Models: Supervised Fine-tuning & GPT3 \\nThe general paradigm brought about by contrastive learning was first to learn a large model on \\nauxiliary tasks created using an unlabelled dataset (the pre-training step) and subsequently to \\nuse these learned representations in a downstream supervised learning task given a few task-\\nspecific labeled examples (the supervised fine-tuning step). While broadly useful and practical, \\nsupervised fine-tuning requires replicas of the baseline pre-trained model for each downstream \\n 9\\nFigure 9: The LLM arms race with exponentially increasing \\nparameter counts. (Credit: HuggingFace)Karan Singh, Assistant Professor of Operations Research \\ntask; further, the large size of language models makes running even a few steps of gradient-\\nbased iterative optimization for supervised learning prohibitive except on computationally \\nexpensive hardware setups. \\nThe paper  describing the architecture of the GPT3 model presents a far cheaper and more 11\\nconvenient way of repurposing pre-trained language models for specific downstream tasks, \\nnamely, by specifying a few labeled examples in the prompt before asking for a label or \\nresponse for unseen data. This mode of inference, in-context learning, does not require \\ncomputationally expensive adjustments to the weights or parameters of an LLM and instead \\ntreats the entire downstream supervised task as a prompt for the language model to complete. \\nThis makes LLMs very attractive for end-users, who no longer have to create copies of the large \\nmodel to customize, nor do they have to run a sophisticated optimization procedure to adjust \\nparameters; each downstream task, in effect, becomes a conversation. While fine-tuning may \\nstill result in additional performance gains over in-context learning for some tasks in exchange \\nfor a massive increase in computational load, a crucial advance of GPT3 is that this \\nsubstantially lowers this gap, democratizing the use (although not the training) of LLMs. \\n \\n 10\\nFigure 10: An illustration of in-context learning. GPT4 figures out the \\ncorrect pattern that the answer is the first number + reverse of the \\nsecond, given two examples.Karan Singh, Assistant Professor of Operations Research \\nTowards Conversational AI: Learning from Human Feedback \\nWhile GPT3-like models happen to be good at conversation-centered tasks, they are not \\nexplicitly trained or incentivized to follow instructions. OpenAI’s InstructGPT model  post pre-12\\ntraining aligns the model to follow the users’ instructions by fine-tuning the model to mimic \\nlabeled demonstrations of the desired behavior (via supervised learning) and highly-ranked \\nresponses to prompts as collected using human feedback (via reinforcement learning). \\n \\nThe Future: Foundation Models \\nGiven the success of language models, there has been increased interest in the possibility of \\nrecreating the magic of LLMs in other domains. Such models, generically termed foundation \\nmodels, attempt to amortize the cost of limited-data downstream tasks by pre-training on large \\ncorpora of broadly related tasks or unlabelled datasets. For example, one might be able to \\nrepurpose the LLM paradigm to train a generalist robot or decision-making agent that learns \\nfrom supply chain operations across all industries. \\nConclusion \\nThis report contextualizes large-language models within the more extensive machine learning \\nand artificial intelligence landscape by training the origins of the principal ideas that fuel today’s \\nlarge language models. By bringing out their essential characteristics and differences against \\ntraditional modes of machine learning, we hope that a user of such models can be better \\n 11\\nFigure 11: While GPT3 performs text completion by guessing the \\nmost plausible completion, InstructGPT has been explicitly \\ntrained to follow instructions. (Credit: OpenAI’s web report)Karan Singh, Assistant Professor of Operations Research \\ninformed of the underlying tradeoffs such models induce, e.g., the performance-resource \\ntradeoffs between fine-tuning and in-context learning. \\nEndnotes \\n See the ﬁrst table on OpenAI’s announcement for an overview of GPT4’s performance on other academic, 1\\nprofessional and programming exams. The quoted nineMeth percenMle performance on the bar exam was assessed \\nby Katz et al, but others have raised concerns. \\n See quotes by industry and research leaders here.2\\n See iniMal consumer adopMon staMsMcs for ChatGPT here and here.3\\n See this reporMng for investments in GenAI.4\\n See current and project user bases for GenAI here.5\\n When producing text, rather than sampling the next word incrementally, a more systemaMc search operaMon 6\\ntermed Beam Search, coined by Raj Reddy at CMU, oXen yields beYer results.\\n Structuring iniMal text to elicit useful outputs from GenAI model is called prompt engineering.7\\n See the full Krizhevshy, Sutskever, Hinton paper here.8\\n See the Word2Vec paper here.9\\n See the paper that introduced Transformers here.10\\n See the GPT3 paper here.11\\n See the instruct GPT paper here.12\\n 12'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chunks\n",
    "from langchain.text_splitter import TokenTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter_ques_gen = TokenTextSplitter(\n",
    "    model_name= \"gpt-3.5-turbo\",\n",
    "    chunk_size= 10000,\n",
    "    chunk_overlap = 200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_ques_gen = splitter_ques_gen.split_text(question_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Karan Singh, Assistant Professor of Operations Research \\nPrinciples of Generative AI \\nA Technical Introduction \\nGenerative artificial intelligence (GenAI) tools are an emerging class of new-age artificial \\nintelligence algorithms capable of producing novel content — in varied formats such as text, \\naudio, video, pictures, and code — based on user prompts. Recent advances in machine \\nlearning (ML), massive datasets, and substantial increases in computing power have propelled \\nsuch tools to human-level performance on academic and professional benchmarks , 1\\ncomparable to the ninetieth percentile on the SAT and the bar exam. \\nThis rapid progress has led many  to to believe that the metamorphosis of these technologies 2\\nfrom research-grade demos to accessible and easy-to-use production-grade goods and \\nservices carries the potential to supercharge business processes and operations while enabling \\nentirely new deliverables heretofore rendered infeasible by economic or technological factors. It \\ntook OpenAI’s ChatGPT, a conversational web app based on a generative (multimodal) \\nlanguage model, about five days to reach one million users  (compared to 2.5 months for 3\\nInstagram). On the business side, the Economist reports that the number of jobs mentioning AI-\\nrelated skills quadrupled from 2022 to 2023. This enthusiasm has not gone unmet by investors. \\nGenerative AI startups reportedly raised 600% more capital in 2022 than in 2020 .   4\\n \\n 1\\nFigure 1: A taxonomy of GenAI-related disciplines.Karan Singh, Assistant Professor of Operations Research \\nPurpose and Scope  \\nWhat are these new-era AI technologies? How do they function? What principles do they \\noperate on? What makes them different than already-hyped-up conventional machine learning \\n(ML) models? For what tasks is this class of technology most impactful? What future advances \\nmight one look forward to? These are the questions this report attempts to shed some light on. \\nThe report will also tease out how this understanding foundationally informs the best uses (and \\nmisuses) of GenAI in applied contexts. \\nA word of disclaimer: this gradient of topics also means that, while the initial sections deal with \\nfactual, if somewhat simplified, nuts-and-bolt workings of such models, the later sections delve \\ninto hopefully reasonable, but in a manner that only time may attest to, extrapolations and \\nspeculations, as necessitated by the developing nature of this technology and its current phase \\nin the technology adoption cycle. \\nWhile generative AI models come in many different shapes, utilizing varied statistical and \\ncomputational techniques to target various modalities, ranging from code and text to audio and \\nvideo, this report focuses almost exclusively on large language models (LLMs) capable of \\ngenerating novel text from textual prompts. This choice is partly due to the substantial lead \\nLLMs have in driving the overall usage of generative AI models  and partly due to the centrality 5\\nof language in formulating and addressing commonplace information-processing tasks. That \\nsaid, image- and code-based GenAI models have already witnessed successful commercial \\nproduct deployment, for example, by Adobe for creating visual content and by Github as a \\nprogramming assistance tool.   \\n 2\\nFigure 2: An image-\\nbased GenAI model, \\nMidjourney’s response to \\nthe prompt — \\n“Businessman in Tokyo \\namidst rush hour, his \\ngaze fixed ahead, \\nsurrounded by a sea of \\nblack umbrellas.”\\nFigure 3: Based on a code-based GenAI model, OpenAI Codex, \\nGithub Copilot is a commercial tool that can generate functional \\ncode from specifications given as natural language. Reportedly, as \\nof June 2023, it served over a million users.Karan Singh, Assistant Professor of Operations Research \\nA Quick First Introduction to Language Models \\nAt its core, a language model implements a simple functionality— to predict the next word (or \\ntoken) given a context window specifying preceding words. More precisely, given a context \\nwindow, a language model outputs a probability distribution over all possible words in its \\nvocabulary, indicating the probability with which each possible word follows the given list of \\nwords. Upon sampling  a guess of the next word from the said distribution, the language model 6\\nincrementally repeats this ostensibly primitive step to produce a more extensive body of text.    \\n \\nWe make two observations here: \\n1. Completions are random. The predicted completion, given a context window, is not \\ndeterministic. Sampling the next word in each step from the output distribution introduces \\nenough randomness to permit that the predicted completions could be meaningfully \\ndifferent on every fresh run. This stochasticity is why ChatGPT, for instance, can offer \\nvaried answers for the same prompt across successive runs. Replacing the sampling step \\nwith choosing (greedily) the most likely immediate word is known to degrade the quality of \\nthe produced text. The randomness in responses is also desirable from a user \\n 3\\nFigure 4: A probabilistic model predicting the next word coupled with sampling can produce \\nlarger bodies of text.Karan Singh, Assistant Professor of Operations Research \\nperspective in getting varied responses. From the deployer’s perspective, this optionally \\nallows the model to gather user feedback regarding the quality of seemingly plausible \\nresponses. This choice partly also contributes to hallucination in language models. \\n2. Initial prompt matters. Language models are conditional probabilistic models. They \\nproduce a completion conditioned on the initial set of words. In this way, the initial context \\nwindow, termed prompt, matters crucially to the produced completion. One hallmark of \\nmodern language models is that they keep track of the initial prompt even when \\ngenerating large bodies of text, unlike the earlier generation of models, thus producing \\nmore coherent responses. Artful and cleverly crafted prompts can significantly improve \\nthe quality and utility of the synthesized text. Prompt engineering , for example, practices 7\\nthat encourage the language model to solve a problem by decomposing it into \\nintermediate subproblems, has been known to improve the performance on logical \\nreasoning tasks. \\nContextualizing LLMs in terms of Recent AI Advances \\nAlthough we describe the text generation procedure above, many questions still need to be \\naddressed: How do language models function internally? How are the output probabilities for \\nthe next word determined? What goes into creating (and indeed using) a language model? How \\nare language models different from more traditional predictive models if all they do is predict the \\nnext token? \\nWe address these questions indirectly in the present section by taking a tour of the essential \\nsignificant developments in machine learning and artificial intelligence that have occurred in the \\nlast decade and have fueled the creation of modern large language models. \\nClassical Machine Learning as Prediction Machines \\nWe start with the most well-understood subset of machine learning techniques: supervised \\nlearning. The central objective in supervised learning is to produce a prediction rule that predicts \\nwell on unseen data, given enough labeled examples. For example, consider predicting house \\nprices from the square footage in a given zip code. Instead of creating a hand-crafted prediction \\nrule, the machine learning methodology advocates for choosing a prediction rule from an \\nexpressive but non-exhaustive class of rules, such as linear predictors, that provides the best fit \\non an existing collection of size-price examples. The statistically well-substantiated leap of faith \\nhere is that we expect (or at least hope) that a parsimonious prediction rule that predicts well on \\ncollected data, for which we know the correct answers, continues to maintain its predictive edge \\non unseen data, where answers or prices are unknown. Such a predictive methodology benefits \\nfrom an abundance of labeled examples, hoping that a prediction rule learned from more \\nexamples is more robust in that its superior predictive performance on seen data is less \\nascribable to chance alone. Another example of a supervised learning task is to separate spam \\nfrom non-spam mail, given the text in email messages. Again, having more examples of spam \\nand non-spam emails is helpful to a supervised learning algorithm. \\n 4Karan Singh, Assistant Professor of Operations Research \\n \\nCharacteristics common to both language models and supervised learning: \\n1. Predicting Well is the Yardstick. A prediction rule is good as long as it makes \\nreasonable predictions on average. Compared to more ambitious sub-disciplines in \\nstatistics, any statements about causality, p-values, and recovering latent structure are \\nabsent. We are similarly impervious to such considerations in language models. Such \\nsimplicity of goals enables very flexible prediction rules in machine learning. Although \\nseeming modest in its aim, the art of machine learning has long been to cast as many \\ndisparate problems as questions about prediction as possible. Predicting house prices \\nfrom square footage is a regular regression task. But, for reverse image captioning, is \\n“predicting” a (high-dimensional) image given a few words a reasonable or well-defined \\nclassification task? Yet, this is how machine learning algorithms function. \\n2. Model Agnosticism. Supervised learning algorithms realize the adage that all models \\nare wrong, but some are useful. For example, when building the price predictor above, a \\ndata scientist does not believe that the genuine relationship between prices and area is \\nlinear or well-specified. Similarly, when using neural networks to predict the next word in \\nlanguage models, we don’t believe that this is how Shakespeare must have employed a \\nneural network to compose his texts. \\nYet, there are crucial differences: \\n 5\\nFigure 5: Predicting house prices from square footage. Pictured is a linear \\nregression, an example of a supervised learning algorithm that uses extant \\ndata to learn a linear predictor.Karan Singh, Assistant Professor of Operations Research \\n1. Fidelity of Seen Data vs. Unseen Data. Classical supervised learning operates on the \\nassumption that seen data must be representative of unseen data in a particular sense, \\nnamely that any fixed example is equally likely to be in the seen or unseen bucket. In the \\nabsence of temporal effects, this is reasonable for house prices. More generally, \\nsupervised learning requires a well-curated dataset that is closely aligned with the \\nprediction task at hand. But, as we will see, language models are trained on vast corpora \\nof somewhat ruthlessly collected texts from the internet. Yet, completing a random partial \\nsentence from the internet is presumably not what businesses using language models \\ncare about. \\nDeep Learning as Automated Representation Learning \\nAlthough useful for panel or tabular data, pre-deep-learning-era supervised algorithms struggled \\nto predict well when presented with visual or auditory inputs. Although the promise of machine \\nlearning is predicated on the automation of learning, in practice, supervised learning algorithms \\nrequire carefully crafted representations of input data in which operations like additions and \\nmultiplications, for example, for linear regression, were semantically relevant. Decades of \\npainstaking research in signal processing and computer vision had resulted in domain-specific \\nhand-crafted representations, each useful for a specific modality (images, audio, or video). The \\npredictive performance of ML algorithms was limited by how good such representations were. \\n 6\\nFigure 6: A typical deep neural network for recognizing faces. Each \\nsuccessive layer progressively learns higher-level representations (from \\nedges to contours to faces).Karan Singh, Assistant Professor of Operations Research \\nThe revolution in deep learning was to automate the process of representation learning itself. \\nDeep learning uses neural networks with multiple layers, each layer incrementally converting \\nthe data into a more manageable form, all to make better predictions. This form of automated \\nhierarchical representation learning heralded a decade of tremendous progress in image and \\nspeech recognition and machine translation, starting with the breakthrough work of Krizhevsky, \\nSutskever, and Hinton  in 2012 on the Imagenet challenge. Taking advantage of GPUs (a form 8\\nof shared-memory parallel computing) and the availability of a large public dataset, this seminal \\nwork slashed the error rate for image recognition by a substantial multiple. Parallel gains were \\nlater realized using similar deep neural network architectures in speech recognition and other \\nmachine learning domains. In this sense, the advances deep learning enabled were (relatively) \\ndomain agnostic. \\nAlthough deep neural networks are data-hungry in that they require a substantially large dataset \\nto start predicting well, they also successfully realize a long-promised advantage of neural \\nnetworks. This factor is crucial to the practice of modern-day machine learning. In the process of \\nhierarchically learning representations, deep nets learn task- (or label--) agnostic features of the \\ndataset in the lower layers, while higher layers closer to the output account for task-specific \\nrepresentations. This permits us to (a) train a deep net to separate images of cats and dogs on \\na large dataset and (b) subsequently build a shallow (even linear) performant neural net that \\nuses the lower layers of the former to craft useful representations to classify images of zebra \\nand giraffes. Step A is often called pre-training, and step B is referred to as supervised fine-\\ntuning. This manner of amortizing the learning across tasks that are not individually data-rich is \\ncentral to language models. \\nWord Embeddings and Contrastive Learning \\nWhile the progress of deep learning in speech and audio was made possible by the availability \\nof large crowd-labeled datasets (with 10s of millions of annotated images), such large high-\\nquality datasets were absent in the textual domain, despite a plethora of unlabelled data in the \\nform of books, Wikipedia articles, and articles on the internet. Could a machine learning \\nalgorithm make use of the cheap, unlabelled data instead? \\nIn computational linguistics, the distributional hypothesis codifies an appealing and intuitive idea \\nthat similar words occur in similar contexts. In 2013, inspired by this observation, Mikolov et al  9\\ntrained a neural network, termed Word2Vec, to predict randomly selected words in a text corpus \\ngiven neighboring words for each. Note that this step doesn’t require any need human \\nannotators. They observed that the 300-dimensional vector representations the neural net \\nlearned for words had excellent linear algebraic properties that transparently reflected the \\nunderlying semantics. For example, one obtained Queen when queried for the word with the \\nvector closest to King - Man + Woman. Thus, each vector dimension captured some abstract \\nsemantic degree of freedom. These representations were also valuable for natural classification \\ntasks with limited data, such as sentiment classification, given a small number of examples. \\n 7Karan Singh, Assistant Professor of Operations Research \\n \\nThe approach of creating auxiliary labeling tasks for free from unlabelled data to learn \\nsemantically relevant representation is called contrastive learning and has proved helpful in \\nother domains, too. For example, given a set of unlabelled images, a classifier trained to \\nrecognize random crops from the same image as a positive match and those from distinct \\nimages as a negative match (pre-training step) learns representations useful for supervised fine-\\ntuning on genuine classification tasks downstream. \\nTransformers mollify the Optimization Landscape \\nWhile word embeddings serve as proof that textual semantic regularities can be assessed \\nwithout labeled data, substantive language processing tasks need an algorithmic \\nimplementation of the concept of memory to capture relationships between words that are \\npositionally far apart. For example, a common motif in stories is that the next act derives from \\nsome event that occurred a while ago.  \\n 8\\nFigure 7: Vector space representations of words exhibit linear algebraic \\nrelationships between semantic units and can be used to answer analogy \\nquestions, e.g., son - father + mother = daughter.\\nFigure 8: RNNs capture memory effects by sequentially processing \\ninformation.Karan Singh, Assistant Professor of Operations Research \\nThe first generation of neural networks that captured the notion of memory were Recurrent \\nNeural Networks (RNNs), by sequentially processing a piece of text one word at a time while \\nupdating an internal state to maintain continuity, a proxy for memory. Unfortunately, optimizing \\nsuch recurrent neural nets to find one that best fits a given dataset proved extra-ordinarily error-\\nprone and challenging. \\nIn 2017, Vaswani et al  introduced a different neural network architecture, termed transformer, 10\\nthat could efficiently capture long-range relations between tokens compactly (non-sequentially) \\nby processing the entire surrounding context window at once while remaining amenable to \\ngradient-based optimization. The introduction of transformers spurred a line of research on \\nlanguage models, culminating in training models with an increasingly higher number of \\nparameters trained on ever larger datasets. For example, GPT2 (Generative Pre-trained \\nTransformer 2), released in 2019, is a 1.5 billion parameter model trained on 40 GB of data, \\nwhile GPT3, released in 2020, is a 175 billion parameter model trained on 570 GB of text data. \\nWhile larger models resulted in better performance, the open-market cost for training these \\nenormous models was estimated to be tens of millions of dollars. \\n \\nGeneral-Purpose Language Models: Supervised Fine-tuning & GPT3 \\nThe general paradigm brought about by contrastive learning was first to learn a large model on \\nauxiliary tasks created using an unlabelled dataset (the pre-training step) and subsequently to \\nuse these learned representations in a downstream supervised learning task given a few task-\\nspecific labeled examples (the supervised fine-tuning step). While broadly useful and practical, \\nsupervised fine-tuning requires replicas of the baseline pre-trained model for each downstream \\n 9\\nFigure 9: The LLM arms race with exponentially increasing \\nparameter counts. (Credit: HuggingFace)Karan Singh, Assistant Professor of Operations Research \\ntask; further, the large size of language models makes running even a few steps of gradient-\\nbased iterative optimization for supervised learning prohibitive except on computationally \\nexpensive hardware setups. \\nThe paper  describing the architecture of the GPT3 model presents a far cheaper and more 11\\nconvenient way of repurposing pre-trained language models for specific downstream tasks, \\nnamely, by specifying a few labeled examples in the prompt before asking for a label or \\nresponse for unseen data. This mode of inference, in-context learning, does not require \\ncomputationally expensive adjustments to the weights or parameters of an LLM and instead \\ntreats the entire downstream supervised task as a prompt for the language model to complete. \\nThis makes LLMs very attractive for end-users, who no longer have to create copies of the large \\nmodel to customize, nor do they have to run a sophisticated optimization procedure to adjust \\nparameters; each downstream task, in effect, becomes a conversation. While fine-tuning may \\nstill result in additional performance gains over in-context learning for some tasks in exchange \\nfor a massive increase in computational load, a crucial advance of GPT3 is that this \\nsubstantially lowers this gap, democratizing the use (although not the training) of LLMs. \\n \\n 10\\nFigure 10: An illustration of in-context learning. GPT4 figures out the \\ncorrect pattern that the answer is the first number + reverse of the \\nsecond, given two examples.Karan Singh, Assistant Professor of Operations Research \\nTowards Conversational AI: Learning from Human Feedback \\nWhile GPT3-like models happen to be good at conversation-centered tasks, they are not \\nexplicitly trained or incentivized to follow instructions. OpenAI’s InstructGPT model  post pre-12\\ntraining aligns the model to follow the users’ instructions by fine-tuning the model to mimic \\nlabeled demonstrations of the desired behavior (via supervised learning) and highly-ranked \\nresponses to prompts as collected using human feedback (via reinforcement learning). \\n \\nThe Future: Foundation Models \\nGiven the success of language models, there has been increased interest in the possibility of \\nrecreating the magic of LLMs in other domains. Such models, generically termed foundation \\nmodels, attempt to amortize the cost of limited-data downstream tasks by pre-training on large \\ncorpora of broadly related tasks or unlabelled datasets. For example, one might be able to \\nrepurpose the LLM paradigm to train a generalist robot or decision-making agent that learns \\nfrom supply chain operations across all industries. \\nConclusion \\nThis report contextualizes large-language models within the more extensive machine learning \\nand artificial intelligence landscape by training the origins of the principal ideas that fuel today’s \\nlarge language models. By bringing out their essential characteristics and differences against \\ntraditional modes of machine learning, we hope that a user of such models can be better \\n 11\\nFigure 11: While GPT3 performs text completion by guessing the \\nmost plausible completion, InstructGPT has been explicitly \\ntrained to follow instructions. (Credit: OpenAI’s web report)Karan Singh, Assistant Professor of Operations Research \\ninformed of the underlying tradeoffs such models induce, e.g., the performance-resource \\ntradeoffs between fine-tuning and in-context learning. \\nEndnotes \\n See the ﬁrst table on OpenAI’s announcement for an overview of GPT4’s performance on other academic, 1\\nprofessional and programming exams. The quoted nineMeth percenMle performance on the bar exam was assessed \\nby Katz et al, but others have raised concerns. \\n See quotes by industry and research leaders here.2\\n See iniMal consumer adopMon staMsMcs for ChatGPT here and here.3\\n See this reporMng for investments in GenAI.4\\n See current and project user bases for GenAI here.5\\n When producing text, rather than sampling the next word incrementally, a more systemaMc search operaMon 6\\ntermed Beam Search, coined by Raj Reddy at CMU, oXen yields beYer results.\\n Structuring iniMal text to elicit useful outputs from GenAI model is called prompt engineering.7\\n See the full Krizhevshy, Sutskever, Hinton paper here.8\\n See the Word2Vec paper here.9\\n See the paper that introduced Transformers here.10\\n See the GPT3 paper here.11\\n See the instruct GPT paper here.12\\n 12']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_ques_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunk_ques_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chunk_ques_gen[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#string to document representation \n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_ques_gen = [Document(page_content = t) for t in chunk_ques_gen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='Karan Singh, Assistant Professor of Operations Research \\nPrinciples of Generative AI \\nA Technical Introduction \\nGenerative artificial intelligence (GenAI) tools are an emerging class of new-age artificial \\nintelligence algorithms capable of producing novel content — in varied formats such as text, \\naudio, video, pictures, and code — based on user prompts. Recent advances in machine \\nlearning (ML), massive datasets, and substantial increases in computing power have propelled \\nsuch tools to human-level performance on academic and professional benchmarks , 1\\ncomparable to the ninetieth percentile on the SAT and the bar exam. \\nThis rapid progress has led many  to to believe that the metamorphosis of these technologies 2\\nfrom research-grade demos to accessible and easy-to-use production-grade goods and \\nservices carries the potential to supercharge business processes and operations while enabling \\nentirely new deliverables heretofore rendered infeasible by economic or technological factors. It \\ntook OpenAI’s ChatGPT, a conversational web app based on a generative (multimodal) \\nlanguage model, about five days to reach one million users  (compared to 2.5 months for 3\\nInstagram). On the business side, the Economist reports that the number of jobs mentioning AI-\\nrelated skills quadrupled from 2022 to 2023. This enthusiasm has not gone unmet by investors. \\nGenerative AI startups reportedly raised 600% more capital in 2022 than in 2020 .   4\\n \\n 1\\nFigure 1: A taxonomy of GenAI-related disciplines.Karan Singh, Assistant Professor of Operations Research \\nPurpose and Scope  \\nWhat are these new-era AI technologies? How do they function? What principles do they \\noperate on? What makes them different than already-hyped-up conventional machine learning \\n(ML) models? For what tasks is this class of technology most impactful? What future advances \\nmight one look forward to? These are the questions this report attempts to shed some light on. \\nThe report will also tease out how this understanding foundationally informs the best uses (and \\nmisuses) of GenAI in applied contexts. \\nA word of disclaimer: this gradient of topics also means that, while the initial sections deal with \\nfactual, if somewhat simplified, nuts-and-bolt workings of such models, the later sections delve \\ninto hopefully reasonable, but in a manner that only time may attest to, extrapolations and \\nspeculations, as necessitated by the developing nature of this technology and its current phase \\nin the technology adoption cycle. \\nWhile generative AI models come in many different shapes, utilizing varied statistical and \\ncomputational techniques to target various modalities, ranging from code and text to audio and \\nvideo, this report focuses almost exclusively on large language models (LLMs) capable of \\ngenerating novel text from textual prompts. This choice is partly due to the substantial lead \\nLLMs have in driving the overall usage of generative AI models  and partly due to the centrality 5\\nof language in formulating and addressing commonplace information-processing tasks. That \\nsaid, image- and code-based GenAI models have already witnessed successful commercial \\nproduct deployment, for example, by Adobe for creating visual content and by Github as a \\nprogramming assistance tool.   \\n 2\\nFigure 2: An image-\\nbased GenAI model, \\nMidjourney’s response to \\nthe prompt — \\n“Businessman in Tokyo \\namidst rush hour, his \\ngaze fixed ahead, \\nsurrounded by a sea of \\nblack umbrellas.”\\nFigure 3: Based on a code-based GenAI model, OpenAI Codex, \\nGithub Copilot is a commercial tool that can generate functional \\ncode from specifications given as natural language. Reportedly, as \\nof June 2023, it served over a million users.Karan Singh, Assistant Professor of Operations Research \\nA Quick First Introduction to Language Models \\nAt its core, a language model implements a simple functionality— to predict the next word (or \\ntoken) given a context window specifying preceding words. More precisely, given a context \\nwindow, a language model outputs a probability distribution over all possible words in its \\nvocabulary, indicating the probability with which each possible word follows the given list of \\nwords. Upon sampling  a guess of the next word from the said distribution, the language model 6\\nincrementally repeats this ostensibly primitive step to produce a more extensive body of text.    \\n \\nWe make two observations here: \\n1. Completions are random. The predicted completion, given a context window, is not \\ndeterministic. Sampling the next word in each step from the output distribution introduces \\nenough randomness to permit that the predicted completions could be meaningfully \\ndifferent on every fresh run. This stochasticity is why ChatGPT, for instance, can offer \\nvaried answers for the same prompt across successive runs. Replacing the sampling step \\nwith choosing (greedily) the most likely immediate word is known to degrade the quality of \\nthe produced text. The randomness in responses is also desirable from a user \\n 3\\nFigure 4: A probabilistic model predicting the next word coupled with sampling can produce \\nlarger bodies of text.Karan Singh, Assistant Professor of Operations Research \\nperspective in getting varied responses. From the deployer’s perspective, this optionally \\nallows the model to gather user feedback regarding the quality of seemingly plausible \\nresponses. This choice partly also contributes to hallucination in language models. \\n2. Initial prompt matters. Language models are conditional probabilistic models. They \\nproduce a completion conditioned on the initial set of words. In this way, the initial context \\nwindow, termed prompt, matters crucially to the produced completion. One hallmark of \\nmodern language models is that they keep track of the initial prompt even when \\ngenerating large bodies of text, unlike the earlier generation of models, thus producing \\nmore coherent responses. Artful and cleverly crafted prompts can significantly improve \\nthe quality and utility of the synthesized text. Prompt engineering , for example, practices 7\\nthat encourage the language model to solve a problem by decomposing it into \\nintermediate subproblems, has been known to improve the performance on logical \\nreasoning tasks. \\nContextualizing LLMs in terms of Recent AI Advances \\nAlthough we describe the text generation procedure above, many questions still need to be \\naddressed: How do language models function internally? How are the output probabilities for \\nthe next word determined? What goes into creating (and indeed using) a language model? How \\nare language models different from more traditional predictive models if all they do is predict the \\nnext token? \\nWe address these questions indirectly in the present section by taking a tour of the essential \\nsignificant developments in machine learning and artificial intelligence that have occurred in the \\nlast decade and have fueled the creation of modern large language models. \\nClassical Machine Learning as Prediction Machines \\nWe start with the most well-understood subset of machine learning techniques: supervised \\nlearning. The central objective in supervised learning is to produce a prediction rule that predicts \\nwell on unseen data, given enough labeled examples. For example, consider predicting house \\nprices from the square footage in a given zip code. Instead of creating a hand-crafted prediction \\nrule, the machine learning methodology advocates for choosing a prediction rule from an \\nexpressive but non-exhaustive class of rules, such as linear predictors, that provides the best fit \\non an existing collection of size-price examples. The statistically well-substantiated leap of faith \\nhere is that we expect (or at least hope) that a parsimonious prediction rule that predicts well on \\ncollected data, for which we know the correct answers, continues to maintain its predictive edge \\non unseen data, where answers or prices are unknown. Such a predictive methodology benefits \\nfrom an abundance of labeled examples, hoping that a prediction rule learned from more \\nexamples is more robust in that its superior predictive performance on seen data is less \\nascribable to chance alone. Another example of a supervised learning task is to separate spam \\nfrom non-spam mail, given the text in email messages. Again, having more examples of spam \\nand non-spam emails is helpful to a supervised learning algorithm. \\n 4Karan Singh, Assistant Professor of Operations Research \\n \\nCharacteristics common to both language models and supervised learning: \\n1. Predicting Well is the Yardstick. A prediction rule is good as long as it makes \\nreasonable predictions on average. Compared to more ambitious sub-disciplines in \\nstatistics, any statements about causality, p-values, and recovering latent structure are \\nabsent. We are similarly impervious to such considerations in language models. Such \\nsimplicity of goals enables very flexible prediction rules in machine learning. Although \\nseeming modest in its aim, the art of machine learning has long been to cast as many \\ndisparate problems as questions about prediction as possible. Predicting house prices \\nfrom square footage is a regular regression task. But, for reverse image captioning, is \\n“predicting” a (high-dimensional) image given a few words a reasonable or well-defined \\nclassification task? Yet, this is how machine learning algorithms function. \\n2. Model Agnosticism. Supervised learning algorithms realize the adage that all models \\nare wrong, but some are useful. For example, when building the price predictor above, a \\ndata scientist does not believe that the genuine relationship between prices and area is \\nlinear or well-specified. Similarly, when using neural networks to predict the next word in \\nlanguage models, we don’t believe that this is how Shakespeare must have employed a \\nneural network to compose his texts. \\nYet, there are crucial differences: \\n 5\\nFigure 5: Predicting house prices from square footage. Pictured is a linear \\nregression, an example of a supervised learning algorithm that uses extant \\ndata to learn a linear predictor.Karan Singh, Assistant Professor of Operations Research \\n1. Fidelity of Seen Data vs. Unseen Data. Classical supervised learning operates on the \\nassumption that seen data must be representative of unseen data in a particular sense, \\nnamely that any fixed example is equally likely to be in the seen or unseen bucket. In the \\nabsence of temporal effects, this is reasonable for house prices. More generally, \\nsupervised learning requires a well-curated dataset that is closely aligned with the \\nprediction task at hand. But, as we will see, language models are trained on vast corpora \\nof somewhat ruthlessly collected texts from the internet. Yet, completing a random partial \\nsentence from the internet is presumably not what businesses using language models \\ncare about. \\nDeep Learning as Automated Representation Learning \\nAlthough useful for panel or tabular data, pre-deep-learning-era supervised algorithms struggled \\nto predict well when presented with visual or auditory inputs. Although the promise of machine \\nlearning is predicated on the automation of learning, in practice, supervised learning algorithms \\nrequire carefully crafted representations of input data in which operations like additions and \\nmultiplications, for example, for linear regression, were semantically relevant. Decades of \\npainstaking research in signal processing and computer vision had resulted in domain-specific \\nhand-crafted representations, each useful for a specific modality (images, audio, or video). The \\npredictive performance of ML algorithms was limited by how good such representations were. \\n 6\\nFigure 6: A typical deep neural network for recognizing faces. Each \\nsuccessive layer progressively learns higher-level representations (from \\nedges to contours to faces).Karan Singh, Assistant Professor of Operations Research \\nThe revolution in deep learning was to automate the process of representation learning itself. \\nDeep learning uses neural networks with multiple layers, each layer incrementally converting \\nthe data into a more manageable form, all to make better predictions. This form of automated \\nhierarchical representation learning heralded a decade of tremendous progress in image and \\nspeech recognition and machine translation, starting with the breakthrough work of Krizhevsky, \\nSutskever, and Hinton  in 2012 on the Imagenet challenge. Taking advantage of GPUs (a form 8\\nof shared-memory parallel computing) and the availability of a large public dataset, this seminal \\nwork slashed the error rate for image recognition by a substantial multiple. Parallel gains were \\nlater realized using similar deep neural network architectures in speech recognition and other \\nmachine learning domains. In this sense, the advances deep learning enabled were (relatively) \\ndomain agnostic. \\nAlthough deep neural networks are data-hungry in that they require a substantially large dataset \\nto start predicting well, they also successfully realize a long-promised advantage of neural \\nnetworks. This factor is crucial to the practice of modern-day machine learning. In the process of \\nhierarchically learning representations, deep nets learn task- (or label--) agnostic features of the \\ndataset in the lower layers, while higher layers closer to the output account for task-specific \\nrepresentations. This permits us to (a) train a deep net to separate images of cats and dogs on \\na large dataset and (b) subsequently build a shallow (even linear) performant neural net that \\nuses the lower layers of the former to craft useful representations to classify images of zebra \\nand giraffes. Step A is often called pre-training, and step B is referred to as supervised fine-\\ntuning. This manner of amortizing the learning across tasks that are not individually data-rich is \\ncentral to language models. \\nWord Embeddings and Contrastive Learning \\nWhile the progress of deep learning in speech and audio was made possible by the availability \\nof large crowd-labeled datasets (with 10s of millions of annotated images), such large high-\\nquality datasets were absent in the textual domain, despite a plethora of unlabelled data in the \\nform of books, Wikipedia articles, and articles on the internet. Could a machine learning \\nalgorithm make use of the cheap, unlabelled data instead? \\nIn computational linguistics, the distributional hypothesis codifies an appealing and intuitive idea \\nthat similar words occur in similar contexts. In 2013, inspired by this observation, Mikolov et al  9\\ntrained a neural network, termed Word2Vec, to predict randomly selected words in a text corpus \\ngiven neighboring words for each. Note that this step doesn’t require any need human \\nannotators. They observed that the 300-dimensional vector representations the neural net \\nlearned for words had excellent linear algebraic properties that transparently reflected the \\nunderlying semantics. For example, one obtained Queen when queried for the word with the \\nvector closest to King - Man + Woman. Thus, each vector dimension captured some abstract \\nsemantic degree of freedom. These representations were also valuable for natural classification \\ntasks with limited data, such as sentiment classification, given a small number of examples. \\n 7Karan Singh, Assistant Professor of Operations Research \\n \\nThe approach of creating auxiliary labeling tasks for free from unlabelled data to learn \\nsemantically relevant representation is called contrastive learning and has proved helpful in \\nother domains, too. For example, given a set of unlabelled images, a classifier trained to \\nrecognize random crops from the same image as a positive match and those from distinct \\nimages as a negative match (pre-training step) learns representations useful for supervised fine-\\ntuning on genuine classification tasks downstream. \\nTransformers mollify the Optimization Landscape \\nWhile word embeddings serve as proof that textual semantic regularities can be assessed \\nwithout labeled data, substantive language processing tasks need an algorithmic \\nimplementation of the concept of memory to capture relationships between words that are \\npositionally far apart. For example, a common motif in stories is that the next act derives from \\nsome event that occurred a while ago.  \\n 8\\nFigure 7: Vector space representations of words exhibit linear algebraic \\nrelationships between semantic units and can be used to answer analogy \\nquestions, e.g., son - father + mother = daughter.\\nFigure 8: RNNs capture memory effects by sequentially processing \\ninformation.Karan Singh, Assistant Professor of Operations Research \\nThe first generation of neural networks that captured the notion of memory were Recurrent \\nNeural Networks (RNNs), by sequentially processing a piece of text one word at a time while \\nupdating an internal state to maintain continuity, a proxy for memory. Unfortunately, optimizing \\nsuch recurrent neural nets to find one that best fits a given dataset proved extra-ordinarily error-\\nprone and challenging. \\nIn 2017, Vaswani et al  introduced a different neural network architecture, termed transformer, 10\\nthat could efficiently capture long-range relations between tokens compactly (non-sequentially) \\nby processing the entire surrounding context window at once while remaining amenable to \\ngradient-based optimization. The introduction of transformers spurred a line of research on \\nlanguage models, culminating in training models with an increasingly higher number of \\nparameters trained on ever larger datasets. For example, GPT2 (Generative Pre-trained \\nTransformer 2), released in 2019, is a 1.5 billion parameter model trained on 40 GB of data, \\nwhile GPT3, released in 2020, is a 175 billion parameter model trained on 570 GB of text data. \\nWhile larger models resulted in better performance, the open-market cost for training these \\nenormous models was estimated to be tens of millions of dollars. \\n \\nGeneral-Purpose Language Models: Supervised Fine-tuning & GPT3 \\nThe general paradigm brought about by contrastive learning was first to learn a large model on \\nauxiliary tasks created using an unlabelled dataset (the pre-training step) and subsequently to \\nuse these learned representations in a downstream supervised learning task given a few task-\\nspecific labeled examples (the supervised fine-tuning step). While broadly useful and practical, \\nsupervised fine-tuning requires replicas of the baseline pre-trained model for each downstream \\n 9\\nFigure 9: The LLM arms race with exponentially increasing \\nparameter counts. (Credit: HuggingFace)Karan Singh, Assistant Professor of Operations Research \\ntask; further, the large size of language models makes running even a few steps of gradient-\\nbased iterative optimization for supervised learning prohibitive except on computationally \\nexpensive hardware setups. \\nThe paper  describing the architecture of the GPT3 model presents a far cheaper and more 11\\nconvenient way of repurposing pre-trained language models for specific downstream tasks, \\nnamely, by specifying a few labeled examples in the prompt before asking for a label or \\nresponse for unseen data. This mode of inference, in-context learning, does not require \\ncomputationally expensive adjustments to the weights or parameters of an LLM and instead \\ntreats the entire downstream supervised task as a prompt for the language model to complete. \\nThis makes LLMs very attractive for end-users, who no longer have to create copies of the large \\nmodel to customize, nor do they have to run a sophisticated optimization procedure to adjust \\nparameters; each downstream task, in effect, becomes a conversation. While fine-tuning may \\nstill result in additional performance gains over in-context learning for some tasks in exchange \\nfor a massive increase in computational load, a crucial advance of GPT3 is that this \\nsubstantially lowers this gap, democratizing the use (although not the training) of LLMs. \\n \\n 10\\nFigure 10: An illustration of in-context learning. GPT4 figures out the \\ncorrect pattern that the answer is the first number + reverse of the \\nsecond, given two examples.Karan Singh, Assistant Professor of Operations Research \\nTowards Conversational AI: Learning from Human Feedback \\nWhile GPT3-like models happen to be good at conversation-centered tasks, they are not \\nexplicitly trained or incentivized to follow instructions. OpenAI’s InstructGPT model  post pre-12\\ntraining aligns the model to follow the users’ instructions by fine-tuning the model to mimic \\nlabeled demonstrations of the desired behavior (via supervised learning) and highly-ranked \\nresponses to prompts as collected using human feedback (via reinforcement learning). \\n \\nThe Future: Foundation Models \\nGiven the success of language models, there has been increased interest in the possibility of \\nrecreating the magic of LLMs in other domains. Such models, generically termed foundation \\nmodels, attempt to amortize the cost of limited-data downstream tasks by pre-training on large \\ncorpora of broadly related tasks or unlabelled datasets. For example, one might be able to \\nrepurpose the LLM paradigm to train a generalist robot or decision-making agent that learns \\nfrom supply chain operations across all industries. \\nConclusion \\nThis report contextualizes large-language models within the more extensive machine learning \\nand artificial intelligence landscape by training the origins of the principal ideas that fuel today’s \\nlarge language models. By bringing out their essential characteristics and differences against \\ntraditional modes of machine learning, we hope that a user of such models can be better \\n 11\\nFigure 11: While GPT3 performs text completion by guessing the \\nmost plausible completion, InstructGPT has been explicitly \\ntrained to follow instructions. (Credit: OpenAI’s web report)Karan Singh, Assistant Professor of Operations Research \\ninformed of the underlying tradeoffs such models induce, e.g., the performance-resource \\ntradeoffs between fine-tuning and in-context learning. \\nEndnotes \\n See the ﬁrst table on OpenAI’s announcement for an overview of GPT4’s performance on other academic, 1\\nprofessional and programming exams. The quoted nineMeth percenMle performance on the bar exam was assessed \\nby Katz et al, but others have raised concerns. \\n See quotes by industry and research leaders here.2\\n See iniMal consumer adopMon staMsMcs for ChatGPT here and here.3\\n See this reporMng for investments in GenAI.4\\n See current and project user bases for GenAI here.5\\n When producing text, rather than sampling the next word incrementally, a more systemaMc search operaMon 6\\ntermed Beam Search, coined by Raj Reddy at CMU, oXen yields beYer results.\\n Structuring iniMal text to elicit useful outputs from GenAI model is called prompt engineering.7\\n See the full Krizhevshy, Sutskever, Hinton paper here.8\\n See the Word2Vec paper here.9\\n See the paper that introduced Transformers here.10\\n See the GPT3 paper here.11\\n See the instruct GPT paper here.12\\n 12')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_ques_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(document_ques_gen[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter_ans_gen = TokenTextSplitter(\n",
    "    model_name = 'gpt-3.5-turbo',\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_answer_gen = splitter_ans_gen.split_documents(\n",
    "    document_ques_gen\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='Karan Singh, Assistant Professor of Operations Research \\nPrinciples of Generative AI \\nA Technical Introduction \\nGenerative artificial intelligence (GenAI) tools are an emerging class of new-age artificial \\nintelligence algorithms capable of producing novel content — in varied formats such as text, \\naudio, video, pictures, and code — based on user prompts. Recent advances in machine \\nlearning (ML), massive datasets, and substantial increases in computing power have propelled \\nsuch tools to human-level performance on academic and professional benchmarks , 1\\ncomparable to the ninetieth percentile on the SAT and the bar exam. \\nThis rapid progress has led many  to to believe that the metamorphosis of these technologies 2\\nfrom research-grade demos to accessible and easy-to-use production-grade goods and \\nservices carries the potential to supercharge business processes and operations while enabling \\nentirely new deliverables heretofore rendered infeasible by economic or technological factors. It \\ntook OpenAI’s ChatGPT, a conversational web app based on a generative (multimodal) \\nlanguage model, about five days to reach one million users  (compared to 2.5 months for 3\\nInstagram). On the business side, the Economist reports that the number of jobs mentioning AI-\\nrelated skills quadrupled from 2022 to 2023. This enthusiasm has not gone unmet by investors. \\nGenerative AI startups reportedly raised 600% more capital in 2022 than in 2020 .   4\\n \\n 1\\nFigure 1: A taxonomy of GenAI-related disciplines.Karan Singh, Assistant Professor of Operations Research \\nPurpose and Scope  \\nWhat are these new-era AI technologies? How do they function? What principles do they \\noperate on? What makes them different than already-hyped-up conventional machine learning \\n(ML) models? For what tasks is this class of technology most impactful? What future advances \\nmight one look forward to? These are the questions this report attempts to shed some light on. \\nThe report will also tease out how this understanding foundationally informs the best uses (and \\nmisuses) of GenAI in applied contexts. \\nA word of disclaimer: this gradient of topics also means that, while the initial sections deal with \\nfactual, if somewhat simplified, nuts-and-bolt workings of such models, the later sections delve \\ninto hopefully reasonable, but in a manner that only time may attest to, extrapolations and \\nspeculations, as necessitated by the developing nature of this technology and its current phase \\nin the technology adoption cycle. \\nWhile generative AI models come in many different shapes, utilizing varied statistical and \\ncomputational techniques to target various modalities, ranging from code and text to audio and \\nvideo, this report focuses almost exclusively on large language models (LLMs) capable of \\ngenerating novel text from textual prompts. This choice is partly due to the substantial lead \\nLLMs have in driving the overall usage of generative AI models  and partly due to the centrality 5\\nof language in formulating and addressing commonplace information-processing tasks. That \\nsaid, image- and code-based GenAI models have already witnessed successful commercial \\nproduct deployment, for example, by Adobe for creating visual content and by Github as a \\nprogramming assistance tool.   \\n 2\\nFigure 2: An image-\\nbased GenAI model, \\nMidjourney’s response to \\nthe prompt — \\n“Businessman in Tokyo \\namidst rush hour, his \\ngaze fixed ahead, \\nsurrounded by a sea of \\nblack umbrellas.”\\nFigure 3: Based on a code-based GenAI model, OpenAI Codex, \\nGithub Copilot is a commercial tool that can generate functional \\ncode from specifications given as natural language. Reportedly, as \\nof June 2023, it served over a million users.Karan Singh, Assistant Professor of Operations Research \\nA Quick First Introduction to Language Models \\nAt its core, a language model implements a simple functionality— to predict the next word (or \\ntoken) given a context window specifying preceding words. More precisely, given a context \\nwindow, a language model outputs a probability distribution over all possible words in its \\nvocabulary, indicating the probability with which each possible word follows the given list of \\nwords. Upon sampling  a guess of the next word from the said distribution, the language model 6\\nincrementally repeats this ostensibly primitive step to produce a more extensive body of text.    \\n \\nWe make two observations here: \\n1. Completions are random. The predicted completion, given a context window, is not \\ndeterministic. Sampling the next word in each step from the output distribution introduces \\nenough randomness to permit that the predicted completions could be meaningfully \\ndifferent on every fresh run. This stochasticity is why ChatGPT, for instance, can offer \\nvaried answers'),\n",
       " Document(metadata={}, page_content='ally repeats this ostensibly primitive step to produce a more extensive body of text.    \\n \\nWe make two observations here: \\n1. Completions are random. The predicted completion, given a context window, is not \\ndeterministic. Sampling the next word in each step from the output distribution introduces \\nenough randomness to permit that the predicted completions could be meaningfully \\ndifferent on every fresh run. This stochasticity is why ChatGPT, for instance, can offer \\nvaried answers for the same prompt across successive runs. Replacing the sampling step \\nwith choosing (greedily) the most likely immediate word is known to degrade the quality of \\nthe produced text. The randomness in responses is also desirable from a user \\n 3\\nFigure 4: A probabilistic model predicting the next word coupled with sampling can produce \\nlarger bodies of text.Karan Singh, Assistant Professor of Operations Research \\nperspective in getting varied responses. From the deployer’s perspective, this optionally \\nallows the model to gather user feedback regarding the quality of seemingly plausible \\nresponses. This choice partly also contributes to hallucination in language models. \\n2. Initial prompt matters. Language models are conditional probabilistic models. They \\nproduce a completion conditioned on the initial set of words. In this way, the initial context \\nwindow, termed prompt, matters crucially to the produced completion. One hallmark of \\nmodern language models is that they keep track of the initial prompt even when \\ngenerating large bodies of text, unlike the earlier generation of models, thus producing \\nmore coherent responses. Artful and cleverly crafted prompts can significantly improve \\nthe quality and utility of the synthesized text. Prompt engineering , for example, practices 7\\nthat encourage the language model to solve a problem by decomposing it into \\nintermediate subproblems, has been known to improve the performance on logical \\nreasoning tasks. \\nContextualizing LLMs in terms of Recent AI Advances \\nAlthough we describe the text generation procedure above, many questions still need to be \\naddressed: How do language models function internally? How are the output probabilities for \\nthe next word determined? What goes into creating (and indeed using) a language model? How \\nare language models different from more traditional predictive models if all they do is predict the \\nnext token? \\nWe address these questions indirectly in the present section by taking a tour of the essential \\nsignificant developments in machine learning and artificial intelligence that have occurred in the \\nlast decade and have fueled the creation of modern large language models. \\nClassical Machine Learning as Prediction Machines \\nWe start with the most well-understood subset of machine learning techniques: supervised \\nlearning. The central objective in supervised learning is to produce a prediction rule that predicts \\nwell on unseen data, given enough labeled examples. For example, consider predicting house \\nprices from the square footage in a given zip code. Instead of creating a hand-crafted prediction \\nrule, the machine learning methodology advocates for choosing a prediction rule from an \\nexpressive but non-exhaustive class of rules, such as linear predictors, that provides the best fit \\non an existing collection of size-price examples. The statistically well-substantiated leap of faith \\nhere is that we expect (or at least hope) that a parsimonious prediction rule that predicts well on \\ncollected data, for which we know the correct answers, continues to maintain its predictive edge \\non unseen data, where answers or prices are unknown. Such a predictive methodology benefits \\nfrom an abundance of labeled examples, hoping that a prediction rule learned from more \\nexamples is more robust in that its superior predictive performance on seen data is less \\nascribable to chance alone. Another example of a supervised learning task is to separate spam \\nfrom non-spam mail, given the text in email messages. Again, having more examples of spam \\nand non-spam emails is helpful to a supervised learning algorithm. \\n 4Karan Singh, Assistant Professor of Operations Research \\n \\nCharacteristics common to both language models and supervised learning: \\n1. Predicting Well is the Yardstick. A prediction rule is good as long as it makes \\nreasonable predictions on average. Compared to more ambitious sub-disciplines in \\nstatistics, any statements about causality, p-values, and recovering latent structure are \\nabsent. We are similarly impervious to such considerations in language models. Such \\nsimplicity of goals enables very flexible prediction rules in machine learning. Although \\nseeming modest in its aim, the art of machine learning has long been to cast as many \\ndisparate problems as questions about prediction as possible. Predicting house prices \\nfrom square footage is a regular regression task. But, for reverse image captioning, is \\n“predicting” a (high-dimensional) image given a few words a reasonable or well-defined \\nclassification task? Yet, this is how machine learning algorithms function. \\n2. Model Agnosticism.'),\n",
       " Document(metadata={}, page_content=' machine learning. Although \\nseeming modest in its aim, the art of machine learning has long been to cast as many \\ndisparate problems as questions about prediction as possible. Predicting house prices \\nfrom square footage is a regular regression task. But, for reverse image captioning, is \\n“predicting” a (high-dimensional) image given a few words a reasonable or well-defined \\nclassification task? Yet, this is how machine learning algorithms function. \\n2. Model Agnosticism. Supervised learning algorithms realize the adage that all models \\nare wrong, but some are useful. For example, when building the price predictor above, a \\ndata scientist does not believe that the genuine relationship between prices and area is \\nlinear or well-specified. Similarly, when using neural networks to predict the next word in \\nlanguage models, we don’t believe that this is how Shakespeare must have employed a \\nneural network to compose his texts. \\nYet, there are crucial differences: \\n 5\\nFigure 5: Predicting house prices from square footage. Pictured is a linear \\nregression, an example of a supervised learning algorithm that uses extant \\ndata to learn a linear predictor.Karan Singh, Assistant Professor of Operations Research \\n1. Fidelity of Seen Data vs. Unseen Data. Classical supervised learning operates on the \\nassumption that seen data must be representative of unseen data in a particular sense, \\nnamely that any fixed example is equally likely to be in the seen or unseen bucket. In the \\nabsence of temporal effects, this is reasonable for house prices. More generally, \\nsupervised learning requires a well-curated dataset that is closely aligned with the \\nprediction task at hand. But, as we will see, language models are trained on vast corpora \\nof somewhat ruthlessly collected texts from the internet. Yet, completing a random partial \\nsentence from the internet is presumably not what businesses using language models \\ncare about. \\nDeep Learning as Automated Representation Learning \\nAlthough useful for panel or tabular data, pre-deep-learning-era supervised algorithms struggled \\nto predict well when presented with visual or auditory inputs. Although the promise of machine \\nlearning is predicated on the automation of learning, in practice, supervised learning algorithms \\nrequire carefully crafted representations of input data in which operations like additions and \\nmultiplications, for example, for linear regression, were semantically relevant. Decades of \\npainstaking research in signal processing and computer vision had resulted in domain-specific \\nhand-crafted representations, each useful for a specific modality (images, audio, or video). The \\npredictive performance of ML algorithms was limited by how good such representations were. \\n 6\\nFigure 6: A typical deep neural network for recognizing faces. Each \\nsuccessive layer progressively learns higher-level representations (from \\nedges to contours to faces).Karan Singh, Assistant Professor of Operations Research \\nThe revolution in deep learning was to automate the process of representation learning itself. \\nDeep learning uses neural networks with multiple layers, each layer incrementally converting \\nthe data into a more manageable form, all to make better predictions. This form of automated \\nhierarchical representation learning heralded a decade of tremendous progress in image and \\nspeech recognition and machine translation, starting with the breakthrough work of Krizhevsky, \\nSutskever, and Hinton  in 2012 on the Imagenet challenge. Taking advantage of GPUs (a form 8\\nof shared-memory parallel computing) and the availability of a large public dataset, this seminal \\nwork slashed the error rate for image recognition by a substantial multiple. Parallel gains were \\nlater realized using similar deep neural network architectures in speech recognition and other \\nmachine learning domains. In this sense, the advances deep learning enabled were (relatively) \\ndomain agnostic. \\nAlthough deep neural networks are data-hungry in that they require a substantially large dataset \\nto start predicting well, they also successfully realize a long-promised advantage of neural \\nnetworks. This factor is crucial to the practice of modern-day machine learning. In the process of \\nhierarchically learning representations, deep nets learn task- (or label--) agnostic features of the \\ndataset in the lower layers, while higher layers closer to the output account for task-specific \\nrepresentations. This permits us to (a) train a deep net to separate images of cats and dogs on \\na large dataset and (b) subsequently build a shallow (even linear) performant neural net that \\nuses the lower layers of the former to craft useful representations to classify images of zebra \\nand giraffes. Step A is often called pre-training, and step B is referred to as supervised fine-\\ntuning. This manner of amortizing the learning across tasks that are not individually data-rich is \\ncentral to language models. \\nWord Embeddings and Contrastive Learning \\nWhile the progress of deep learning in speech and audio was'),\n",
       " Document(metadata={}, page_content=' subsequently build a shallow (even linear) performant neural net that \\nuses the lower layers of the former to craft useful representations to classify images of zebra \\nand giraffes. Step A is often called pre-training, and step B is referred to as supervised fine-\\ntuning. This manner of amortizing the learning across tasks that are not individually data-rich is \\ncentral to language models. \\nWord Embeddings and Contrastive Learning \\nWhile the progress of deep learning in speech and audio was made possible by the availability \\nof large crowd-labeled datasets (with 10s of millions of annotated images), such large high-\\nquality datasets were absent in the textual domain, despite a plethora of unlabelled data in the \\nform of books, Wikipedia articles, and articles on the internet. Could a machine learning \\nalgorithm make use of the cheap, unlabelled data instead? \\nIn computational linguistics, the distributional hypothesis codifies an appealing and intuitive idea \\nthat similar words occur in similar contexts. In 2013, inspired by this observation, Mikolov et al  9\\ntrained a neural network, termed Word2Vec, to predict randomly selected words in a text corpus \\ngiven neighboring words for each. Note that this step doesn’t require any need human \\nannotators. They observed that the 300-dimensional vector representations the neural net \\nlearned for words had excellent linear algebraic properties that transparently reflected the \\nunderlying semantics. For example, one obtained Queen when queried for the word with the \\nvector closest to King - Man + Woman. Thus, each vector dimension captured some abstract \\nsemantic degree of freedom. These representations were also valuable for natural classification \\ntasks with limited data, such as sentiment classification, given a small number of examples. \\n 7Karan Singh, Assistant Professor of Operations Research \\n \\nThe approach of creating auxiliary labeling tasks for free from unlabelled data to learn \\nsemantically relevant representation is called contrastive learning and has proved helpful in \\nother domains, too. For example, given a set of unlabelled images, a classifier trained to \\nrecognize random crops from the same image as a positive match and those from distinct \\nimages as a negative match (pre-training step) learns representations useful for supervised fine-\\ntuning on genuine classification tasks downstream. \\nTransformers mollify the Optimization Landscape \\nWhile word embeddings serve as proof that textual semantic regularities can be assessed \\nwithout labeled data, substantive language processing tasks need an algorithmic \\nimplementation of the concept of memory to capture relationships between words that are \\npositionally far apart. For example, a common motif in stories is that the next act derives from \\nsome event that occurred a while ago.  \\n 8\\nFigure 7: Vector space representations of words exhibit linear algebraic \\nrelationships between semantic units and can be used to answer analogy \\nquestions, e.g., son - father + mother = daughter.\\nFigure 8: RNNs capture memory effects by sequentially processing \\ninformation.Karan Singh, Assistant Professor of Operations Research \\nThe first generation of neural networks that captured the notion of memory were Recurrent \\nNeural Networks (RNNs), by sequentially processing a piece of text one word at a time while \\nupdating an internal state to maintain continuity, a proxy for memory. Unfortunately, optimizing \\nsuch recurrent neural nets to find one that best fits a given dataset proved extra-ordinarily error-\\nprone and challenging. \\nIn 2017, Vaswani et al  introduced a different neural network architecture, termed transformer, 10\\nthat could efficiently capture long-range relations between tokens compactly (non-sequentially) \\nby processing the entire surrounding context window at once while remaining amenable to \\ngradient-based optimization. The introduction of transformers spurred a line of research on \\nlanguage models, culminating in training models with an increasingly higher number of \\nparameters trained on ever larger datasets. For example, GPT2 (Generative Pre-trained \\nTransformer 2), released in 2019, is a 1.5 billion parameter model trained on 40 GB of data, \\nwhile GPT3, released in 2020, is a 175 billion parameter model trained on 570 GB of text data. \\nWhile larger models resulted in better performance, the open-market cost for training these \\nenormous models was estimated to be tens of millions of dollars. \\n \\nGeneral-Purpose Language Models: Supervised Fine-tuning & GPT3 \\nThe general paradigm brought about by contrastive learning was first to learn a large model on \\nauxiliary tasks created using an unlabelled dataset (the pre-training step) and subsequently to \\nuse these learned representations in a downstream supervised learning task given a few task-\\nspecific labeled examples (the supervised fine-tuning step). While broadly useful and practical, \\nsupervised fine-tuning requires replicas of the baseline pre-trained model for each downstream \\n 9\\nFigure 9'),\n",
       " Document(metadata={}, page_content='uning & GPT3 \\nThe general paradigm brought about by contrastive learning was first to learn a large model on \\nauxiliary tasks created using an unlabelled dataset (the pre-training step) and subsequently to \\nuse these learned representations in a downstream supervised learning task given a few task-\\nspecific labeled examples (the supervised fine-tuning step). While broadly useful and practical, \\nsupervised fine-tuning requires replicas of the baseline pre-trained model for each downstream \\n 9\\nFigure 9: The LLM arms race with exponentially increasing \\nparameter counts. (Credit: HuggingFace)Karan Singh, Assistant Professor of Operations Research \\ntask; further, the large size of language models makes running even a few steps of gradient-\\nbased iterative optimization for supervised learning prohibitive except on computationally \\nexpensive hardware setups. \\nThe paper  describing the architecture of the GPT3 model presents a far cheaper and more 11\\nconvenient way of repurposing pre-trained language models for specific downstream tasks, \\nnamely, by specifying a few labeled examples in the prompt before asking for a label or \\nresponse for unseen data. This mode of inference, in-context learning, does not require \\ncomputationally expensive adjustments to the weights or parameters of an LLM and instead \\ntreats the entire downstream supervised task as a prompt for the language model to complete. \\nThis makes LLMs very attractive for end-users, who no longer have to create copies of the large \\nmodel to customize, nor do they have to run a sophisticated optimization procedure to adjust \\nparameters; each downstream task, in effect, becomes a conversation. While fine-tuning may \\nstill result in additional performance gains over in-context learning for some tasks in exchange \\nfor a massive increase in computational load, a crucial advance of GPT3 is that this \\nsubstantially lowers this gap, democratizing the use (although not the training) of LLMs. \\n \\n 10\\nFigure 10: An illustration of in-context learning. GPT4 figures out the \\ncorrect pattern that the answer is the first number + reverse of the \\nsecond, given two examples.Karan Singh, Assistant Professor of Operations Research \\nTowards Conversational AI: Learning from Human Feedback \\nWhile GPT3-like models happen to be good at conversation-centered tasks, they are not \\nexplicitly trained or incentivized to follow instructions. OpenAI’s InstructGPT model  post pre-12\\ntraining aligns the model to follow the users’ instructions by fine-tuning the model to mimic \\nlabeled demonstrations of the desired behavior (via supervised learning) and highly-ranked \\nresponses to prompts as collected using human feedback (via reinforcement learning). \\n \\nThe Future: Foundation Models \\nGiven the success of language models, there has been increased interest in the possibility of \\nrecreating the magic of LLMs in other domains. Such models, generically termed foundation \\nmodels, attempt to amortize the cost of limited-data downstream tasks by pre-training on large \\ncorpora of broadly related tasks or unlabelled datasets. For example, one might be able to \\nrepurpose the LLM paradigm to train a generalist robot or decision-making agent that learns \\nfrom supply chain operations across all industries. \\nConclusion \\nThis report contextualizes large-language models within the more extensive machine learning \\nand artificial intelligence landscape by training the origins of the principal ideas that fuel today’s \\nlarge language models. By bringing out their essential characteristics and differences against \\ntraditional modes of machine learning, we hope that a user of such models can be better \\n 11\\nFigure 11: While GPT3 performs text completion by guessing the \\nmost plausible completion, InstructGPT has been explicitly \\ntrained to follow instructions. (Credit: OpenAI’s web report)Karan Singh, Assistant Professor of Operations Research \\ninformed of the underlying tradeoffs such models induce, e.g., the performance-resource \\ntradeoffs between fine-tuning and in-context learning. \\nEndnotes \\n See the ﬁrst table on OpenAI’s announcement for an overview of GPT4’s performance on other academic, 1\\nprofessional and programming exams. The quoted nineMeth percenMle performance on the bar exam was assessed \\nby Katz et al, but others have raised concerns. \\n See quotes by industry and research leaders here.2\\n See iniMal consumer adopMon staMsMcs for ChatGPT here and here.3\\n See this reporMng for investments in GenAI.4\\n See current and project user bases for GenAI here.5\\n When producing text, rather than sampling the next word incrementally, a more systemaMc search operaMon 6\\ntermed Beam Search, coined by Raj Reddy at CMU, oXen yields beYer results.\\n Structuring iniMal text to elicit useful outputs from GenAI model is called prompt engineering.7\\n See'),\n",
       " Document(metadata={}, page_content=' here.3\\n See this reporMng for investments in GenAI.4\\n See current and project user bases for GenAI here.5\\n When producing text, rather than sampling the next word incrementally, a more systemaMc search operaMon 6\\ntermed Beam Search, coined by Raj Reddy at CMU, oXen yields beYer results.\\n Structuring iniMal text to elicit useful outputs from GenAI model is called prompt engineering.7\\n See the full Krizhevshy, Sutskever, Hinton paper here.8\\n See the Word2Vec paper here.9\\n See the paper that introduced Transformers here.10\\n See the GPT3 paper here.11\\n See the instruct GPT paper here.12\\n 12')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_answer_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(document_answer_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question & Answering generation\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_20436\\1473655646.py:1: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm_ques_gen_pipeline = ChatOpenAI(\n"
     ]
    }
   ],
   "source": [
    "llm_ques_gen_pipeline = ChatOpenAI(\n",
    "    model = 'gpt-3.5-turbo',\n",
    "    temperature = 0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are an expert at creating questions based on coding materials and documentation.\n",
    "Your goal is to prepare a coder or programmer for their exam and coding tests.\n",
    "You do this by asking questions about the text below:\n",
    "\n",
    "------------\n",
    "{text}\n",
    "------------\n",
    "\n",
    "Create questions that will prepare the coders or programmers for their tests.\n",
    "Make sure not to lose any important information.\n",
    "\n",
    "QUESTIONS:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_QUESTIONS = PromptTemplate(template=prompt_template, input_variables=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "refine_template = (\"\"\"\n",
    "You are an expert at creating practice questions based on coding material and documentation.\n",
    "Your goal is to help a coder or programmer prepare for a coding test.\n",
    "We have received some practice questions to a certain extent: {existing_answer}.\n",
    "We have the option to refine the existing questions or add new ones.\n",
    "(only if necessary) with some more context below.\n",
    "------------\n",
    "{text}\n",
    "------------\n",
    "\n",
    "Given the new context, refine the original questions in English.\n",
    "If the context is not helpful, please provide the original questions.\n",
    "QUESTIONS:\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "REFINE_PROMPT_QUESTIONS = PromptTemplate(\n",
    "    input_variables=[\"existing_answer\", \"text\"],\n",
    "    template=refine_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ques_gen_chain = load_summarize_chain(llm = llm_ques_gen_pipeline, \n",
    "                                          chain_type = \"refine\", \n",
    "                                          verbose = True, \n",
    "                                          question_prompt=PROMPT_QUESTIONS, \n",
    "                                          refine_prompt=REFINE_PROMPT_QUESTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_20436\\3836958406.py:1: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  ques = ques_gen_chain.run(document_ques_gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RefineDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are an expert at creating questions based on coding materials and documentation.\n",
      "Your goal is to prepare a coder or programmer for their exam and coding tests.\n",
      "You do this by asking questions about the text below:\n",
      "\n",
      "------------\n",
      "Karan Singh, Assistant Professor of Operations Research \n",
      "Principles of Generative AI \n",
      "A Technical Introduction \n",
      "Generative artificial intelligence (GenAI) tools are an emerging class of new-age artificial \n",
      "intelligence algorithms capable of producing novel content — in varied formats such as text, \n",
      "audio, video, pictures, and code — based on user prompts. Recent advances in machine \n",
      "learning (ML), massive datasets, and substantial increases in computing power have propelled \n",
      "such tools to human-level performance on academic and professional benchmarks , 1\n",
      "comparable to the ninetieth percentile on the SAT and the bar exam. \n",
      "This rapid progress has led many  to to believe that the metamorphosis of these technologies 2\n",
      "from research-grade demos to accessible and easy-to-use production-grade goods and \n",
      "services carries the potential to supercharge business processes and operations while enabling \n",
      "entirely new deliverables heretofore rendered infeasible by economic or technological factors. It \n",
      "took OpenAI’s ChatGPT, a conversational web app based on a generative (multimodal) \n",
      "language model, about five days to reach one million users  (compared to 2.5 months for 3\n",
      "Instagram). On the business side, the Economist reports that the number of jobs mentioning AI-\n",
      "related skills quadrupled from 2022 to 2023. This enthusiasm has not gone unmet by investors. \n",
      "Generative AI startups reportedly raised 600% more capital in 2022 than in 2020 .   4\n",
      " \n",
      " 1\n",
      "Figure 1: A taxonomy of GenAI-related disciplines.Karan Singh, Assistant Professor of Operations Research \n",
      "Purpose and Scope  \n",
      "What are these new-era AI technologies? How do they function? What principles do they \n",
      "operate on? What makes them different than already-hyped-up conventional machine learning \n",
      "(ML) models? For what tasks is this class of technology most impactful? What future advances \n",
      "might one look forward to? These are the questions this report attempts to shed some light on. \n",
      "The report will also tease out how this understanding foundationally informs the best uses (and \n",
      "misuses) of GenAI in applied contexts. \n",
      "A word of disclaimer: this gradient of topics also means that, while the initial sections deal with \n",
      "factual, if somewhat simplified, nuts-and-bolt workings of such models, the later sections delve \n",
      "into hopefully reasonable, but in a manner that only time may attest to, extrapolations and \n",
      "speculations, as necessitated by the developing nature of this technology and its current phase \n",
      "in the technology adoption cycle. \n",
      "While generative AI models come in many different shapes, utilizing varied statistical and \n",
      "computational techniques to target various modalities, ranging from code and text to audio and \n",
      "video, this report focuses almost exclusively on large language models (LLMs) capable of \n",
      "generating novel text from textual prompts. This choice is partly due to the substantial lead \n",
      "LLMs have in driving the overall usage of generative AI models  and partly due to the centrality 5\n",
      "of language in formulating and addressing commonplace information-processing tasks. That \n",
      "said, image- and code-based GenAI models have already witnessed successful commercial \n",
      "product deployment, for example, by Adobe for creating visual content and by Github as a \n",
      "programming assistance tool.   \n",
      " 2\n",
      "Figure 2: An image-\n",
      "based GenAI model, \n",
      "Midjourney’s response to \n",
      "the prompt — \n",
      "“Businessman in Tokyo \n",
      "amidst rush hour, his \n",
      "gaze fixed ahead, \n",
      "surrounded by a sea of \n",
      "black umbrellas.”\n",
      "Figure 3: Based on a code-based GenAI model, OpenAI Codex, \n",
      "Github Copilot is a commercial tool that can generate functional \n",
      "code from specifications given as natural language. Reportedly, as \n",
      "of June 2023, it served over a million users.Karan Singh, Assistant Professor of Operations Research \n",
      "A Quick First Introduction to Language Models \n",
      "At its core, a language model implements a simple functionality— to predict the next word (or \n",
      "token) given a context window specifying preceding words. More precisely, given a context \n",
      "window, a language model outputs a probability distribution over all possible words in its \n",
      "vocabulary, indicating the probability with which each possible word follows the given list of \n",
      "words. Upon sampling  a guess of the next word from the said distribution, the language model 6\n",
      "incrementally repeats this ostensibly primitive step to produce a more extensive body of text.    \n",
      " \n",
      "We make two observations here: \n",
      "1. Completions are random. The predicted completion, given a context window, is not \n",
      "deterministic. Sampling the next word in each step from the output distribution introduces \n",
      "enough randomness to permit that the predicted completions could be meaningfully \n",
      "different on every fresh run. This stochasticity is why ChatGPT, for instance, can offer \n",
      "varied answers for the same prompt across successive runs. Replacing the sampling step \n",
      "with choosing (greedily) the most likely immediate word is known to degrade the quality of \n",
      "the produced text. The randomness in responses is also desirable from a user \n",
      " 3\n",
      "Figure 4: A probabilistic model predicting the next word coupled with sampling can produce \n",
      "larger bodies of text.Karan Singh, Assistant Professor of Operations Research \n",
      "perspective in getting varied responses. From the deployer’s perspective, this optionally \n",
      "allows the model to gather user feedback regarding the quality of seemingly plausible \n",
      "responses. This choice partly also contributes to hallucination in language models. \n",
      "2. Initial prompt matters. Language models are conditional probabilistic models. They \n",
      "produce a completion conditioned on the initial set of words. In this way, the initial context \n",
      "window, termed prompt, matters crucially to the produced completion. One hallmark of \n",
      "modern language models is that they keep track of the initial prompt even when \n",
      "generating large bodies of text, unlike the earlier generation of models, thus producing \n",
      "more coherent responses. Artful and cleverly crafted prompts can significantly improve \n",
      "the quality and utility of the synthesized text. Prompt engineering , for example, practices 7\n",
      "that encourage the language model to solve a problem by decomposing it into \n",
      "intermediate subproblems, has been known to improve the performance on logical \n",
      "reasoning tasks. \n",
      "Contextualizing LLMs in terms of Recent AI Advances \n",
      "Although we describe the text generation procedure above, many questions still need to be \n",
      "addressed: How do language models function internally? How are the output probabilities for \n",
      "the next word determined? What goes into creating (and indeed using) a language model? How \n",
      "are language models different from more traditional predictive models if all they do is predict the \n",
      "next token? \n",
      "We address these questions indirectly in the present section by taking a tour of the essential \n",
      "significant developments in machine learning and artificial intelligence that have occurred in the \n",
      "last decade and have fueled the creation of modern large language models. \n",
      "Classical Machine Learning as Prediction Machines \n",
      "We start with the most well-understood subset of machine learning techniques: supervised \n",
      "learning. The central objective in supervised learning is to produce a prediction rule that predicts \n",
      "well on unseen data, given enough labeled examples. For example, consider predicting house \n",
      "prices from the square footage in a given zip code. Instead of creating a hand-crafted prediction \n",
      "rule, the machine learning methodology advocates for choosing a prediction rule from an \n",
      "expressive but non-exhaustive class of rules, such as linear predictors, that provides the best fit \n",
      "on an existing collection of size-price examples. The statistically well-substantiated leap of faith \n",
      "here is that we expect (or at least hope) that a parsimonious prediction rule that predicts well on \n",
      "collected data, for which we know the correct answers, continues to maintain its predictive edge \n",
      "on unseen data, where answers or prices are unknown. Such a predictive methodology benefits \n",
      "from an abundance of labeled examples, hoping that a prediction rule learned from more \n",
      "examples is more robust in that its superior predictive performance on seen data is less \n",
      "ascribable to chance alone. Another example of a supervised learning task is to separate spam \n",
      "from non-spam mail, given the text in email messages. Again, having more examples of spam \n",
      "and non-spam emails is helpful to a supervised learning algorithm. \n",
      " 4Karan Singh, Assistant Professor of Operations Research \n",
      " \n",
      "Characteristics common to both language models and supervised learning: \n",
      "1. Predicting Well is the Yardstick. A prediction rule is good as long as it makes \n",
      "reasonable predictions on average. Compared to more ambitious sub-disciplines in \n",
      "statistics, any statements about causality, p-values, and recovering latent structure are \n",
      "absent. We are similarly impervious to such considerations in language models. Such \n",
      "simplicity of goals enables very flexible prediction rules in machine learning. Although \n",
      "seeming modest in its aim, the art of machine learning has long been to cast as many \n",
      "disparate problems as questions about prediction as possible. Predicting house prices \n",
      "from square footage is a regular regression task. But, for reverse image captioning, is \n",
      "“predicting” a (high-dimensional) image given a few words a reasonable or well-defined \n",
      "classification task? Yet, this is how machine learning algorithms function. \n",
      "2. Model Agnosticism. Supervised learning algorithms realize the adage that all models \n",
      "are wrong, but some are useful. For example, when building the price predictor above, a \n",
      "data scientist does not believe that the genuine relationship between prices and area is \n",
      "linear or well-specified. Similarly, when using neural networks to predict the next word in \n",
      "language models, we don’t believe that this is how Shakespeare must have employed a \n",
      "neural network to compose his texts. \n",
      "Yet, there are crucial differences: \n",
      " 5\n",
      "Figure 5: Predicting house prices from square footage. Pictured is a linear \n",
      "regression, an example of a supervised learning algorithm that uses extant \n",
      "data to learn a linear predictor.Karan Singh, Assistant Professor of Operations Research \n",
      "1. Fidelity of Seen Data vs. Unseen Data. Classical supervised learning operates on the \n",
      "assumption that seen data must be representative of unseen data in a particular sense, \n",
      "namely that any fixed example is equally likely to be in the seen or unseen bucket. In the \n",
      "absence of temporal effects, this is reasonable for house prices. More generally, \n",
      "supervised learning requires a well-curated dataset that is closely aligned with the \n",
      "prediction task at hand. But, as we will see, language models are trained on vast corpora \n",
      "of somewhat ruthlessly collected texts from the internet. Yet, completing a random partial \n",
      "sentence from the internet is presumably not what businesses using language models \n",
      "care about. \n",
      "Deep Learning as Automated Representation Learning \n",
      "Although useful for panel or tabular data, pre-deep-learning-era supervised algorithms struggled \n",
      "to predict well when presented with visual or auditory inputs. Although the promise of machine \n",
      "learning is predicated on the automation of learning, in practice, supervised learning algorithms \n",
      "require carefully crafted representations of input data in which operations like additions and \n",
      "multiplications, for example, for linear regression, were semantically relevant. Decades of \n",
      "painstaking research in signal processing and computer vision had resulted in domain-specific \n",
      "hand-crafted representations, each useful for a specific modality (images, audio, or video). The \n",
      "predictive performance of ML algorithms was limited by how good such representations were. \n",
      " 6\n",
      "Figure 6: A typical deep neural network for recognizing faces. Each \n",
      "successive layer progressively learns higher-level representations (from \n",
      "edges to contours to faces).Karan Singh, Assistant Professor of Operations Research \n",
      "The revolution in deep learning was to automate the process of representation learning itself. \n",
      "Deep learning uses neural networks with multiple layers, each layer incrementally converting \n",
      "the data into a more manageable form, all to make better predictions. This form of automated \n",
      "hierarchical representation learning heralded a decade of tremendous progress in image and \n",
      "speech recognition and machine translation, starting with the breakthrough work of Krizhevsky, \n",
      "Sutskever, and Hinton  in 2012 on the Imagenet challenge. Taking advantage of GPUs (a form 8\n",
      "of shared-memory parallel computing) and the availability of a large public dataset, this seminal \n",
      "work slashed the error rate for image recognition by a substantial multiple. Parallel gains were \n",
      "later realized using similar deep neural network architectures in speech recognition and other \n",
      "machine learning domains. In this sense, the advances deep learning enabled were (relatively) \n",
      "domain agnostic. \n",
      "Although deep neural networks are data-hungry in that they require a substantially large dataset \n",
      "to start predicting well, they also successfully realize a long-promised advantage of neural \n",
      "networks. This factor is crucial to the practice of modern-day machine learning. In the process of \n",
      "hierarchically learning representations, deep nets learn task- (or label--) agnostic features of the \n",
      "dataset in the lower layers, while higher layers closer to the output account for task-specific \n",
      "representations. This permits us to (a) train a deep net to separate images of cats and dogs on \n",
      "a large dataset and (b) subsequently build a shallow (even linear) performant neural net that \n",
      "uses the lower layers of the former to craft useful representations to classify images of zebra \n",
      "and giraffes. Step A is often called pre-training, and step B is referred to as supervised fine-\n",
      "tuning. This manner of amortizing the learning across tasks that are not individually data-rich is \n",
      "central to language models. \n",
      "Word Embeddings and Contrastive Learning \n",
      "While the progress of deep learning in speech and audio was made possible by the availability \n",
      "of large crowd-labeled datasets (with 10s of millions of annotated images), such large high-\n",
      "quality datasets were absent in the textual domain, despite a plethora of unlabelled data in the \n",
      "form of books, Wikipedia articles, and articles on the internet. Could a machine learning \n",
      "algorithm make use of the cheap, unlabelled data instead? \n",
      "In computational linguistics, the distributional hypothesis codifies an appealing and intuitive idea \n",
      "that similar words occur in similar contexts. In 2013, inspired by this observation, Mikolov et al  9\n",
      "trained a neural network, termed Word2Vec, to predict randomly selected words in a text corpus \n",
      "given neighboring words for each. Note that this step doesn’t require any need human \n",
      "annotators. They observed that the 300-dimensional vector representations the neural net \n",
      "learned for words had excellent linear algebraic properties that transparently reflected the \n",
      "underlying semantics. For example, one obtained Queen when queried for the word with the \n",
      "vector closest to King - Man + Woman. Thus, each vector dimension captured some abstract \n",
      "semantic degree of freedom. These representations were also valuable for natural classification \n",
      "tasks with limited data, such as sentiment classification, given a small number of examples. \n",
      " 7Karan Singh, Assistant Professor of Operations Research \n",
      " \n",
      "The approach of creating auxiliary labeling tasks for free from unlabelled data to learn \n",
      "semantically relevant representation is called contrastive learning and has proved helpful in \n",
      "other domains, too. For example, given a set of unlabelled images, a classifier trained to \n",
      "recognize random crops from the same image as a positive match and those from distinct \n",
      "images as a negative match (pre-training step) learns representations useful for supervised fine-\n",
      "tuning on genuine classification tasks downstream. \n",
      "Transformers mollify the Optimization Landscape \n",
      "While word embeddings serve as proof that textual semantic regularities can be assessed \n",
      "without labeled data, substantive language processing tasks need an algorithmic \n",
      "implementation of the concept of memory to capture relationships between words that are \n",
      "positionally far apart. For example, a common motif in stories is that the next act derives from \n",
      "some event that occurred a while ago.  \n",
      " 8\n",
      "Figure 7: Vector space representations of words exhibit linear algebraic \n",
      "relationships between semantic units and can be used to answer analogy \n",
      "questions, e.g., son - father + mother = daughter.\n",
      "Figure 8: RNNs capture memory effects by sequentially processing \n",
      "information.Karan Singh, Assistant Professor of Operations Research \n",
      "The first generation of neural networks that captured the notion of memory were Recurrent \n",
      "Neural Networks (RNNs), by sequentially processing a piece of text one word at a time while \n",
      "updating an internal state to maintain continuity, a proxy for memory. Unfortunately, optimizing \n",
      "such recurrent neural nets to find one that best fits a given dataset proved extra-ordinarily error-\n",
      "prone and challenging. \n",
      "In 2017, Vaswani et al  introduced a different neural network architecture, termed transformer, 10\n",
      "that could efficiently capture long-range relations between tokens compactly (non-sequentially) \n",
      "by processing the entire surrounding context window at once while remaining amenable to \n",
      "gradient-based optimization. The introduction of transformers spurred a line of research on \n",
      "language models, culminating in training models with an increasingly higher number of \n",
      "parameters trained on ever larger datasets. For example, GPT2 (Generative Pre-trained \n",
      "Transformer 2), released in 2019, is a 1.5 billion parameter model trained on 40 GB of data, \n",
      "while GPT3, released in 2020, is a 175 billion parameter model trained on 570 GB of text data. \n",
      "While larger models resulted in better performance, the open-market cost for training these \n",
      "enormous models was estimated to be tens of millions of dollars. \n",
      " \n",
      "General-Purpose Language Models: Supervised Fine-tuning & GPT3 \n",
      "The general paradigm brought about by contrastive learning was first to learn a large model on \n",
      "auxiliary tasks created using an unlabelled dataset (the pre-training step) and subsequently to \n",
      "use these learned representations in a downstream supervised learning task given a few task-\n",
      "specific labeled examples (the supervised fine-tuning step). While broadly useful and practical, \n",
      "supervised fine-tuning requires replicas of the baseline pre-trained model for each downstream \n",
      " 9\n",
      "Figure 9: The LLM arms race with exponentially increasing \n",
      "parameter counts. (Credit: HuggingFace)Karan Singh, Assistant Professor of Operations Research \n",
      "task; further, the large size of language models makes running even a few steps of gradient-\n",
      "based iterative optimization for supervised learning prohibitive except on computationally \n",
      "expensive hardware setups. \n",
      "The paper  describing the architecture of the GPT3 model presents a far cheaper and more 11\n",
      "convenient way of repurposing pre-trained language models for specific downstream tasks, \n",
      "namely, by specifying a few labeled examples in the prompt before asking for a label or \n",
      "response for unseen data. This mode of inference, in-context learning, does not require \n",
      "computationally expensive adjustments to the weights or parameters of an LLM and instead \n",
      "treats the entire downstream supervised task as a prompt for the language model to complete. \n",
      "This makes LLMs very attractive for end-users, who no longer have to create copies of the large \n",
      "model to customize, nor do they have to run a sophisticated optimization procedure to adjust \n",
      "parameters; each downstream task, in effect, becomes a conversation. While fine-tuning may \n",
      "still result in additional performance gains over in-context learning for some tasks in exchange \n",
      "for a massive increase in computational load, a crucial advance of GPT3 is that this \n",
      "substantially lowers this gap, democratizing the use (although not the training) of LLMs. \n",
      " \n",
      " 10\n",
      "Figure 10: An illustration of in-context learning. GPT4 figures out the \n",
      "correct pattern that the answer is the first number + reverse of the \n",
      "second, given two examples.Karan Singh, Assistant Professor of Operations Research \n",
      "Towards Conversational AI: Learning from Human Feedback \n",
      "While GPT3-like models happen to be good at conversation-centered tasks, they are not \n",
      "explicitly trained or incentivized to follow instructions. OpenAI’s InstructGPT model  post pre-12\n",
      "training aligns the model to follow the users’ instructions by fine-tuning the model to mimic \n",
      "labeled demonstrations of the desired behavior (via supervised learning) and highly-ranked \n",
      "responses to prompts as collected using human feedback (via reinforcement learning). \n",
      " \n",
      "The Future: Foundation Models \n",
      "Given the success of language models, there has been increased interest in the possibility of \n",
      "recreating the magic of LLMs in other domains. Such models, generically termed foundation \n",
      "models, attempt to amortize the cost of limited-data downstream tasks by pre-training on large \n",
      "corpora of broadly related tasks or unlabelled datasets. For example, one might be able to \n",
      "repurpose the LLM paradigm to train a generalist robot or decision-making agent that learns \n",
      "from supply chain operations across all industries. \n",
      "Conclusion \n",
      "This report contextualizes large-language models within the more extensive machine learning \n",
      "and artificial intelligence landscape by training the origins of the principal ideas that fuel today’s \n",
      "large language models. By bringing out their essential characteristics and differences against \n",
      "traditional modes of machine learning, we hope that a user of such models can be better \n",
      " 11\n",
      "Figure 11: While GPT3 performs text completion by guessing the \n",
      "most plausible completion, InstructGPT has been explicitly \n",
      "trained to follow instructions. (Credit: OpenAI’s web report)Karan Singh, Assistant Professor of Operations Research \n",
      "informed of the underlying tradeoffs such models induce, e.g., the performance-resource \n",
      "tradeoffs between fine-tuning and in-context learning. \n",
      "Endnotes \n",
      " See the ﬁrst table on OpenAI’s announcement for an overview of GPT4’s performance on other academic, 1\n",
      "professional and programming exams. The quoted nineMeth percenMle performance on the bar exam was assessed \n",
      "by Katz et al, but others have raised concerns. \n",
      " See quotes by industry and research leaders here.2\n",
      " See iniMal consumer adopMon staMsMcs for ChatGPT here and here.3\n",
      " See this reporMng for investments in GenAI.4\n",
      " See current and project user bases for GenAI here.5\n",
      " When producing text, rather than sampling the next word incrementally, a more systemaMc search operaMon 6\n",
      "termed Beam Search, coined by Raj Reddy at CMU, oXen yields beYer results.\n",
      " Structuring iniMal text to elicit useful outputs from GenAI model is called prompt engineering.7\n",
      " See the full Krizhevshy, Sutskever, Hinton paper here.8\n",
      " See the Word2Vec paper here.9\n",
      " See the paper that introduced Transformers here.10\n",
      " See the GPT3 paper here.11\n",
      " See the instruct GPT paper here.12\n",
      " 12\n",
      "------------\n",
      "\n",
      "Create questions that will prepare the coders or programmers for their tests.\n",
      "Make sure not to lose any important information.\n",
      "\n",
      "QUESTIONS:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "1. What are generative artificial intelligence (GenAI) tools capable of producing?\n",
      "2. How has recent advances in machine learning, massive datasets, and computing power impacted the performance of GenAI tools?\n",
      "3. What is the purpose of large language models (LLMs) in the context of generative AI?\n",
      "4. How do language models operate in predicting the next word given a context window?\n",
      "5. What are the two key observations mentioned in the text regarding language models?\n",
      "6. How do supervised learning algorithms differ from language models in terms of predicting well and model agnosticism?\n",
      "7. What is the significance of word embeddings and contrastive learning in the development of language models?\n",
      "8. How did the introduction of transformers revolutionize the field of language models?\n",
      "9. What is the concept of in-context learning in the context of language models like GPT3?\n",
      "10. What are foundation models, and how do they aim to leverage the success of large language models in other domains?\n"
     ]
    }
   ],
   "source": [
    "ques = ques_gen_chain.run(document_ques_gen)\n",
    "\n",
    "print(ques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embedding \n",
    "from langchain.embeddings.openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_20436\\2497576997.py:1: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings()\n"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vector data base \n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = FAISS.from_documents(document_answer_gen, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_answer_gen = ChatOpenAI(temperature=0.1, model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. What are generative artificial intelligence (GenAI) tools capable of producing?\\n2. How has recent advances in machine learning, massive datasets, and computing power impacted the performance of GenAI tools?\\n3. What is the purpose of large language models (LLMs) in the context of generative AI?\\n4. How do language models operate in predicting the next word given a context window?\\n5. What are the two key observations mentioned in the text regarding language models?\\n6. How do supervised learning algorithms differ from language models in terms of predicting well and model agnosticism?\\n7. What is the significance of word embeddings and contrastive learning in the development of language models?\\n8. How did the introduction of transformers revolutionize the field of language models?\\n9. What is the concept of in-context learning in the context of language models like GPT3?\\n10. What are foundation models, and how do they aim to leverage the success of large language models in other domains?'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ques_list = ques.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. What are generative artificial intelligence (GenAI) tools capable of producing?',\n",
       " '2. How has recent advances in machine learning, massive datasets, and computing power impacted the performance of GenAI tools?',\n",
       " '3. What is the purpose of large language models (LLMs) in the context of generative AI?',\n",
       " '4. How do language models operate in predicting the next word given a context window?',\n",
       " '5. What are the two key observations mentioned in the text regarding language models?',\n",
       " '6. How do supervised learning algorithms differ from language models in terms of predicting well and model agnosticism?',\n",
       " '7. What is the significance of word embeddings and contrastive learning in the development of language models?',\n",
       " '8. How did the introduction of transformers revolutionize the field of language models?',\n",
       " '9. What is the concept of in-context learning in the context of language models like GPT3?',\n",
       " '10. What are foundation models, and how do they aim to leverage the success of large language models in other domains?']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ques_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q's&An'set\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_generation_chain = RetrievalQA.from_chain_type(llm=llm_answer_gen, \n",
    "                                               chain_type=\"stuff\", \n",
    "                                               retriever=vector_store.as_retriever())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  1. What are generative artificial intelligence (GenAI) tools capable of producing?\n",
      "Answer:  Generative artificial intelligence (GenAI) tools are capable of producing novel content in various formats such as text, audio, video, pictures, and code based on user prompts.\n",
      "--------------------------------------------------\\n\\n\n",
      "Question:  2. How has recent advances in machine learning, massive datasets, and computing power impacted the performance of GenAI tools?\n",
      "Answer:  Recent advances in machine learning, massive datasets, and substantial increases in computing power have propelled Generative AI (GenAI) tools to human-level performance on academic and professional benchmarks. These advancements have enabled GenAI tools to achieve performance levels comparable to the ninetieth percentile on the SAT and the bar exam. The progress in these areas has also led to the rapid development of GenAI tools from research-grade demos to accessible and easy-to-use production-grade goods and services, potentially supercharging business processes and operations.\n",
      "--------------------------------------------------\\n\\n\n",
      "Question:  3. What is the purpose of large language models (LLMs) in the context of generative AI?\n",
      "Answer:  Large Language Models (LLMs) play a crucial role in generative AI by enabling the generation of novel content, such as text, based on user prompts. These models are designed to predict the next word or token given a context window of preceding words, allowing them to generate coherent and contextually relevant text. LLMs leverage their vast pre-training on large corpora of text data to understand language patterns and semantics, making them adept at producing human-like text responses. In the context of generative AI, LLMs serve as powerful tools for creating diverse content across various modalities, including text, audio, video, and more, based on user inputs or prompts.\n",
      "--------------------------------------------------\\n\\n\n",
      "Question:  4. How do language models operate in predicting the next word given a context window?\n",
      "Answer:  Language models operate by predicting the next word given a context window through conditional probabilistic modeling. They produce a completion based on the initial set of words, known as the prompt, which is crucial to the produced completion. The models keep track of the initial prompt even when generating large bodies of text, unlike earlier models, to produce more coherent responses. The predictions are stochastic, meaning they are not deterministic, and sampling the next word introduces enough randomness to provide varied answers for the same prompt across successive runs. This randomness is desirable for getting varied responses and allows the model to gather user feedback on the quality of responses. The initial prompt and prompt engineering play a significant role in improving the quality and utility of the synthesized text.\n",
      "--------------------------------------------------\\n\\n\n",
      "Question:  5. What are the two key observations mentioned in the text regarding language models?\n",
      "Answer:  The two key observations mentioned in the text regarding language models are:\n",
      "\n",
      "1. Completions are random: Predicted completions are not deterministic. Sampling the next word from the output distribution introduces enough randomness, leading to varied answers on each fresh run.\n",
      "\n",
      "2. Initial prompt matters: Language models are conditional probabilistic models. The initial prompt or context window crucially influences the produced completion, and well-crafted prompts can significantly improve the quality and coherence of the synthesized text.\n",
      "--------------------------------------------------\\n\\n\n",
      "Question:  6. How do supervised learning algorithms differ from language models in terms of predicting well and model agnosticism?\n",
      "Answer:  Supervised learning algorithms and language models differ in terms of predicting well and model agnosticism. \n",
      "\n",
      "1. Predicting Well: \n",
      "- Supervised learning algorithms focus on making reasonable predictions on average based on labeled examples. They aim to predict well on unseen data by learning from known data.\n",
      "- Language models, on the other hand, predict the next word or token based on the context provided. They focus on generating coherent text rather than predicting outcomes in the traditional sense.\n",
      "\n",
      "2. Model Agnosticism:\n",
      "- Supervised learning algorithms acknowledge that all models are wrong but some are useful. They aim to choose the best model from a class of rules that fits the data well.\n",
      "- Language models, especially modern ones like GPT-3, use neural networks to predict the next word. They do not assume that the model structure reflects the true underlying relationships in the data but rather focus on generating text based on learned patterns.\n",
      "\n",
      "In summary, supervised learning algorithms are more focused on prediction tasks with labeled data, while language models are more about generating text based on learned patterns and context.\n",
      "--------------------------------------------------\\n\\n\n",
      "Question:  7. What is the significance of word embeddings and contrastive learning in the development of language models?\n",
      "Answer:  Word embeddings and contrastive learning play a significant role in the development of language models. Word embeddings, such as Word2Vec, provide a way to represent words in a vector space that captures semantic relationships between words. These embeddings are valuable for natural language processing tasks like sentiment classification, even with limited data.\n",
      "\n",
      "On the other hand, contrastive learning is an approach that creates auxiliary labeling tasks from unlabelled data to learn semantically relevant representations. By training models on tasks like recognizing random crops from images as positive or negative matches, contrastive learning helps in learning useful representations for downstream tasks.\n",
      "\n",
      "Both word embeddings and contrastive learning contribute to the ability of language models to understand and generate text by capturing semantic relationships and learning from unlabelled data efficiently.\n",
      "--------------------------------------------------\\n\\n\n",
      "Question:  8. How did the introduction of transformers revolutionize the field of language models?\n",
      "Answer:  The introduction of transformers revolutionized the field of language models by efficiently capturing long-range relations between tokens non-sequentially. Unlike Recurrent Neural Networks (RNNs) that process text sequentially, transformers process the entire surrounding context window at once. This approach allows transformers to capture complex relationships between words that are positionally far apart, leading to better performance in natural language processing tasks. Additionally, transformers are amenable to gradient-based optimization, making them easier to train compared to RNNs. This advancement spurred a line of research on language models, resulting in the development of increasingly larger models like GPT2 and GPT3, trained on massive datasets, and significantly improving performance in various language-related tasks.\n",
      "--------------------------------------------------\\n\\n\n",
      "Question:  9. What is the concept of in-context learning in the context of language models like GPT3?\n",
      "Answer:  In the context of language models like GPT3, in-context learning is a concept where the model is repurposed for specific downstream tasks by specifying a few labeled examples in the prompt before asking for a label or response for unseen data. This mode of inference does not require computationally expensive adjustments to the weights or parameters of the model. Instead, the entire downstream supervised task is treated as a prompt for the language model to complete, making it more convenient and cost-effective for end-users.\n",
      "--------------------------------------------------\\n\\n\n",
      "Question:  10. What are foundation models, and how do they aim to leverage the success of large language models in other domains?\n",
      "Answer:  Foundation models, also known as generically termed foundation models, aim to leverage the success of large language models in other domains by pre-training on large corpora of broadly related tasks or unlabelled datasets. The idea is to amortize the cost of limited-data downstream tasks by using the pre-training step to learn semantically relevant representations that can be repurposed for various tasks. For example, one application could be training a generalist robot or decision-making agent that learns from supply chain operations across all industries. The goal is to extend the benefits of large language models to other domains by using the learned representations to tackle a wide range of tasks beyond language processing.\n",
      "--------------------------------------------------\\n\\n\n"
     ]
    }
   ],
   "source": [
    "# Answer each question and save to a file\n",
    "for question in ques_list:\n",
    "    print(\"Question: \", question)\n",
    "    answer = answer_generation_chain.run(question)\n",
    "    print(\"Answer: \", answer)\n",
    "    print(\"--------------------------------------------------\\\\n\\\\n\")\n",
    "    # Save answer to file\n",
    "    with open(\"answers.txt\", \"a\") as f:\n",
    "        f.write(\"Question: \" + question + \"\\\\n\")\n",
    "        f.write(\"Answer: \" + answer + \"\\\\n\")\n",
    "        f.write(\"--------------------------------------------------\\\\n\\\\n\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interview",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
